@misc{supercomp,
  author = {Bookman,Samantha},
  title = {{15 Supercomputers Less Powerful Than Your Phone}},
  howpublished = "\url{https://www.theclever.com/15-huge-supercomputers-that-were-less-powerful-than-your-smartphone/}",
  year = {2015}, 
  note = "[Online; accessed 02-April-2019]"
}

@book{James2013,
abstract = {An Introduction to Statisitcal Learning with Applications in R},
author = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
doi = {10.1007/978-1-4614-7138-7},
isbn = {978-1-4614-7137-0},
pages = {337--342},
title = {{An Introduction to Statistical Learning}},
year = {2013}
}

@misc{leeSedol,
  author = {Silver, David},
  title = {{The story of AlphaGo so far}},
  howpublished = "\url{https://deepmind.com/research/alphago/}",
  year = {2016}, 
  note = "[Online; accessed 14-April-2019]"
}

@misc{hedgefundRets,
  author = {Kaissar, Nir},
  title = {{Hedge Funds have a Performance Problem}},
  howpublished = "\url{https://www.bloomberg.com/opinion/articles/2016-03-24/hedge-funds-have-a-performance-problem}",
  year = {2016}, 
  note = "[Online; accessed 04-April-2019]"
}


@misc{bestdays,
  author = {Batwick, Michael},
  title = {{How missing out on 25 days in the stock market over 45 years costs you dearly}},
  howpublished = "\url{https://www.marketwatch.com/story/how-missing-out-on-25-days-in-the-stock-market-over-45-years-costs-you-dearly-2016-01-25 }",
  year = {2016}, 
  note = "[Online; accessed 31-March-2019]"
}


@misc{medium,
  author = {Yoann, Berno},
  title = {{The Truth Nobody Wants to Tell You About AI for Trading}},
  howpublished = "\url{https://hackernoon.com/https-medium\\-com-supernova-the-truth-nobody-wants-to-tell-you-about-ai-for-trading-5d29a297ee93}",
  year = {2019}, 
  note = "[Online; accessed 31-March-2019]"
}
@misc{anomalydetection,
  author = {Schölkopf, Bernhard},
  title = {{Sci-Kit Learn: Novelty and Outlier Detection}},
  howpublished = "\url{https://scikit-learn.org/stable/modules/outlier_detection.html}",
  year = {2019}, 
  note = "[Online; accessed 06-April-2019]"
}


@misc{kerneltrick,
  author = {Wilimitis, Derek},
  title = {{The Kernel Trick in Support Vector Classification}},
  howpublished = "\url{https://towardsdatascience.com/the-kernel-trick-c98cdbcaeb3f}",
  year = {2018}, 
  note = "[Online; accessed 07-April-2019]"
}








@article{Huang2005,
abstract = {Support vector machine (SVM) is a very specific type of learning algorithms characterized by the capacity control of the decision function, the use of the kernel functions and the sparsity of the solution. In this paper, we investigate the predictability of financial movement direction with SVM by forecasting the weekly movement direction of NIKKEI 225 index. To evaluate the forecasting ability of SVM, we compare its performance with those of Linear Discriminant Analysis, Quadratic Discriminant Analysis and Elman Backpropagation Neural Networks. The experiment results show that SVM outperforms the other classification methods. Further, we propose a combining model by integrating SVM with the other classification methods. The combining model performs best among all the forecasting methods. {\textcopyright} 2004 Elsevier Ltd. All rights reserved.},
author = {Huang, Wei and Nakamori, Yoshiteru and Wang, Shou Yang},
doi = {10.1016/j.cor.2004.03.016},
issn = {03050548},
journal = {Computers and Operations Research},
keywords = {Forecasting,Multivariate classification,Support vector machine},
title = {{Forecasting stock market movement direction with support vector machine}},
year = {2005}
}
@article{Dymova2016,
abstract = {Currently FOREX (foreign exchange market) is the largest financial market over the world. Usually the Forex market analysis is based on the Forex time series prediction. Nevertheless, trading expert systems based on such predictions do not usually provide satisfactory results. On the other hand, stock trading expert systems called also "mechanical trading systems", which are based on the technical analysis, are very popular and may provide good profits. Therefore, in this paper we propose a Forex trading expert system based on some new technical analysis indicators and a new approach to the rule-base evidential reasoning (RBER) (the synthesis of fuzzy logic and the Dempster-Shafer theory of evidence). We have found that the traditional fuzzy logic rules lose an important information, when dealing with the intersecting fuzzy classes, e.g., such as Low and Medium and we have shown that this property may lead to the controversial results in practice. In the framework of the proposed in the current paper new approach, an information of the values of all membership functions representing the intersecting (competing) fuzzy classes is preserved and used in the fuzzy logic rules. The advantages of the proposed approach are demonstrated using the developed expert system optimized and tested on the real data from the Forex market for the four currency pairs and the time frames 15 m, 30 m, 1 h and 4 h.},
author = {Dymova, Ludmila and Sevastjanov, Pavel and Kaczmarek, Krzysztof},
doi = {10.1016/j.eswa.2015.12.028},
isbn = {0957-4174},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Dempster-Shafer theory,Expert system,Forex,Fuzzy logic,Rule-base evidential reasoning,Technical analysis},
title = {{A Forex trading expert system based on a new approach to the rule-base evidential reasoning}},
year = {2016}
}
@article{Bailey2014,
abstract = {With the advent in recent years of large financial data sets, machine learning and high-performance computing, analysts can backtest millions (if not billions) of alternative investment strategies. Backtest optimizers search for combinations of parameters that maximize the simulated historical performance of a strategy, leading to backtest overfitting. The problem of performance inflation extends beyond backtesting. More generally, researchers and investors tend to report only positive outcomes, a phenomenon known as selection bias. Not controlling for the number of trials involved in a particular discovery leads to over-optimistic performance expectations. The Deflated Sharpe Ratio (DSR) corrects for two leading sources of performance inflation: Selection bias under multiple testing and non-Normally distributed returns. In doing so, DSR helps separate legitimate empirical findings from statistical flukes.},
author = {Bailey, David H. and {Lopez de Prado}, Marcos},
doi = {10.2139/ssrn.2460551},
issn = {0095-4918},
journal = {SSRN},
keywords = {Backtest overfitting,E44,G0,G1,G15,G2,G24,Minimum Backtest Length,Minimum Track Record Length,Non-Normality,Probabilistic Sharpe ratio,Sharpe ratio},
title = {{The Deflated Sharpe Ratio: Correcting for Selection Bias, Backtest Overfitting and Non-Normality}},
year = {2014}
}
@inproceedings{Joarder2003,
abstract = {In today's global economy, accuracy in forecasting the foreign exchange rate or at least predicting the trend correctly is of crucial importance for any future investment. The use of computational intelligence based techniques for forecasting has been proved extremely successful in recent times. In this paper, we developed and investigated three artificial neural network (ANN) based forecasting model using standard backpropagation (SBP), scaled conjugate gradient (SCG) and backpropagation with Baysian regularization (BPR) for Australian foreign exchange to predict six different currencies against Australian dollar. Five moving average technical indicators are used to build the models. These models were evaluated on five performance metrics and a comparison was made with traditional ARIMA model. All the ANN based models outperform ARIMA model. It is found that SCG based model performs best when measured on the two most commonly used metrics and shows competitive results when compared with BPR based model on other three metrics. Experimental results demonstrate that ANN based model can closely forecast the forex market.},
author = {Joarder, Kamruzzaman and Sarker, Ruhul A.},
booktitle = {Proceedings of 2003 International Conference on Neural Networks and Signal Processing, ICNNSP'03},
doi = {10.1109/ICNNSP.2003.1279395},
isbn = {0780377028},
title = {{Forecasting of currency exchange rates using ANN: A case study}},
year = {2003}
}
@unpublished{LopezdePrado2015,
abstract = {This paper introduces the Hierarchical Risk Parity (HRP) approach. HRP portfolios address three major concerns of quadratic optimizers in general and Markowitz's CLA in particular: Instability, concentration and underperformance.  HRP applies modern mathematics (graph theory and machine learning techniques) to build a diversified portfolio based on the information contained in the covariance matrix. However, unlike quadratic optimizers, HRP does not require the invertibility of the covariance matrix. In fact, HRP can compute a portfolio on an ill-degenerated or even a singular covariance matrix, an impossible feat for quadratic optimizers. Monte Carlo experiments show that HRP delivers lower out-of-sample variance than CLA, even though minimum-variance is CLA's optimization objective. HRP also produces less risky portfolios out-of-sample compared to traditional risk parity methods.  A presentation can be found at {\textless}a href='http://ssrn.com/abstract=2713516'{\textgreater}http://ssrn.com/abstract=2713516{\textless}/a{\textgreater}.},
author = {{Lopez de Prado}, Marcos},
booktitle = {SSRN},
doi = {10.2139/ssrn.2708678},
keywords = {E44,G0,G1,G15,G2,G24,Risk parity,cluster,dendogram,linkage,metric space,tree graph},
title = {{Building Diversified Portfolios that Outperform Out-of-Sample}},
year = {2015}
}
@article{Koedijk2016,
abstract = {In this paper we investigate and evaluate factor investing in the US and Europe for equities and bonds. We show that factor‐based portfolios generally produce comparable or better portfolios than market indices. We expand the analysis to other asset classes and factors, work with other optimisation methods and add a basic liability structure. The results do not depend on adding other asset classes or on the removal of a specific factor. Finally, we study the results for a worldwide investor who invests beyond the US and Europe. Over the longer term and with consistently applied factor diversification, factor investing appears to be advantageous. },
archivePrefix = {arXiv},
arxivId = {1503.02531},
author = {Koedijk, Kees G. and Slager, Alfred M.H. and Stork, Philip A.},
doi = {10.1111/eufm.12081},
eprint = {1503.02531},
isbn = {3531207857},
issn = {1468036X},
journal = {European Financial Management},
keywords = {Diversification,Factor investing,Optimisation,Portfolio management},
pmid = {18249735},
title = {{Investing in Systematic Factor Premiums}},
year = {2016}
}
@article{Christiansen2011,
abstract = {We explain the currency carry trade performance using an asset pricing model in which factor loadings are regime-dependent rather than constant. Empirical results show that a typical carry trade strategy has much higher exposure to the stock market and is mean-reverting in regimes of high FX volatility. The findings are robust to various extensions. Our regime-dependent pricing model provides significantly smaller pricing errors than a traditional model. Thus, the carry trade performance is better explained by a time-varying systematic risk that increases in volatile markets, suggesting a partial resolution of the Uncovered Interest Rate parity puzzle.},
author = {Christiansen, Charlotte and Ranaldo, Angelo and S{\"{o}}derlind, Paul},
doi = {10.1017/S0022109011000263},
issn = {00221090},
journal = {Journal of Financial and Quantitative Analysis},
title = {{The time-varying systematic risk of carry trade strategies}},
year = {2011}
}
@article{Kim2000,
abstract = {This paper proposes genetic algorithms (GAs) approach to feature discretization and the determination of connection weights for artificial neural networks (ANNs) to predict the stock price index. Previous research proposed many hybrid models of ANN and GA for the method of training the network, feature subset selection, and topology optimization. In most of these studies, however, GA is only used to improve the learning algorithm itself. In this study, GA is employed not only to improve the learning algorithm, but also to reduce the complexity in feature space. GA optimizes simultaneously the connection weights between layers and the thresholds for feature discretization. The genetically evolved weights mitigate the well-known limitations of the gradient descent algorithm. In addition, globally searched feature discretization reduces the dimensionality of the feature space and eliminates irrelevant factors. Experimental results show that GA approach to the feature discretization model outperforms the other two conventional models.},
author = {Kim, Kyoung Jae and Han, Ingoo},
doi = {10.1016/S0957-4174(00)00027-0},
issn = {09574174},
journal = {Expert Systems with Applications},
title = {{Genetic algorithms approach to feature discretization in artificial neural networks for the prediction of stock price index}},
year = {2000}
}
@misc{Silver2016,
abstract = {Games are a great testing ground for developing smarter, more flexible algorithms that have the ability to tackle problems in ways similar to humans. Creating programs that are able to play games better than the best humans has a long history - the first classic game mastered by a computer was noughts and crosses (also known as tic-tac-toe) in 1952 as a PhD candidate's project. Then fell checkers in 1994. Chess was tackled by Deep Blue in 1997. The success isn't limited to board games, either - IBM's Watson won first place on Jeopardy in 2011, and in 2014 our own algorithms learned to play dozens of Atari games just from the raw pixel inputs.},
author = {Silver, David and Hassabis, Demis},
booktitle = {Google Research Blog},
title = {{AlphaGo: Mastering the ancient game of Go with Machine Learning}},
url = {https://ai.googleblog.com/2016/01/alphago-mastering-ancient-game-of-go.html},
year = {2016}
}
@article{Sharpe2009,
abstract = {Over twenty-five years ago, in sharpe (1966) I introduced a measure for the performance of mutual funds and proposed the term reward-to-variability ratio to descripe it (the measure is also descriped in Sharpe [1975]). While the measure has gained considerable popularity, the name has not. Other authors have termed the original version the Sharpe index (Radcliff [1990, p. 286] and Haugen [1993, p. 315]), the Sharpe Measure (Bodie, Kane, and Marcus [1993, p. 804], Elton and Gruber [1991, p. 652], and Reilly [1993, p. 24]), or the Sharpe Ratio (Morningstar [1993, p. 24]). Generalized versions have also appeared under various names (see, for example, BARRA [1992, P. 21] and Capaul, Rowley, and Sharpe [1993, p. 33]). Bowing to increasingly common usage, this article refers to both the original measure and more generalized versions as the Sharpe Ratio. My goal here is to go well beyond the discussion of the original measure in Sharpe [1966] and Sharpe [1975], providing more generality and covering a broader range of applications.},
author = {Sharpe, William F.},
doi = {10.3905/jpm.1994.409501},
issn = {0095-4918},
journal = {The Journal of Portfolio Management},
title = {{The Sharpe Ratio}},
year = {2009}
}
@inproceedings{Nguyen2013,
abstract = {Stock price forecast has long been received special attention of investors and financial institutions. As stock prices are changeable over time and increasingly uncertain in modern financial markets, their forecasting becomes more important than ever before. A hybrid approach consisting of two components, a neural network and a fuzzy logic system, is proposed in this paper for stock price prediction. The first component of the hybrid, i.e. a feedforward neural network (FFNN), is used to select inputs that are highly relevant to the dependent variables. An interval type-2 fuzzy logic system (IT2 FLS) is employed as the second component of the hybrid forecasting method. The IT2 FLS's parameters are initialized through deployment of the k-means clustering method and they are adjusted by the genetic algorithm. Experimental results demonstrate the efficiency of the FFNN input selection approach as it reduces the complexity and increase the accuracy of the forecasting models. In addition, IT2 FLS outperforms the widely used type-1 FLS and FFNN models in stock price forecasting. The combination of the FFNN and the IT2 FLS produces dominant forecasting accuracy compared to employing only the IT2 FLSs without the FFNN input selection.},
author = {Nguyen, T. and Khosravi, A. and Nahavandi, S. and Creighton, D.},
booktitle = {IEEE International Conference on Fuzzy Systems},
doi = {10.1109/FUZZ-IEEE.2013.6622370},
isbn = {9781479900220},
issn = {10987584},
keywords = {Feedforward neural network,Genetic algorithm,Input selection,Interval type-2 fuzzy system,K-means clustering,Stock price forecasting},
title = {{Neural network and interval type-2 fuzzy system for stock price forecasting}},
year = {2013}
}
@incollection{Hill2016,
abstract = {networkx},
author = {Hill, Christian and Hill, Christian},
booktitle = {Learning Scientific Programming with Python},
doi = {10.1017/cbo9781139871754.007},
title = {{Matplotlib}},
year = {2016}
}
@article{Breiman2001,
abstract = {Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the corre- lation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund {\&} R. Schapire, Machine Learning: Proceedings of the Thirteenth Interna- tional conference, ∗∗∗, 148–156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression. Keywords:},
author = {Breiman, Leo},
journal = {Machine learning},
title = {{Random Forrests}},
year = {2001}
}
@article{Ozturk2016a,
abstract = {Technical indicators are widely used in Forex and other financial markets which are the building blocks of many trading systems. A trading system is based on technical indicators or pattern-based approaches which produces buy/sell signals to trade in the market. In this paper, a heuristic based trading system on Forex data, which is developed using popular technical indicators is presented. The system grounds on selecting and combining the trading rules based on indicators using heuristic methods. The selection of the trading rules is realized by using Genetic algorithm and a greedy search heuristic. A weighted majority voting method is proposed to combine the technical indicator based trading rules to form a single trading rule. The experiments are conducted on 2 major currency pairs in 3 different time frames where promising results are achieved.},
author = {Ozturk, Murat and Toroslu, Ismail Hakki and Fidan, Guven},
doi = {10.1016/j.asoc.2016.01.048},
issn = {15684946},
journal = {Applied Soft Computing Journal},
keywords = {Forex,Genetic algorithm,Heuristic methods,Technical analysis,Technical indicator,Trading rule,Trading system},
pages = {170--186},
title = {{Heuristic based trading system on Forex data using technical indicator rules}},
volume = {43},
year = {2016}
}
@article{CaZorzi2016,
abstract = {This paper brings four new insights into the Purchasing Power Parity (PPP) debate. First, we show that a half-life PPP (HL) model is able to forecast real exchange rates better than the random walk (RW) model at both short and long-term horizons. Second, we find that this result holds if the speed of adjustment to the sample mean is calibrated at reasonable values rather than estimated. Third, we find that it is preferable to calibrate, rather than to elicit as a prior, the parameter determining the speed of adjustment to PPP. Fourth, for most currencies in our sample, the HL model outperforms the RW also in terms of nominal effective exchange rate forecasting.},
author = {{Ca' Zorzi}, Michele and Muck, Jakub and Rubaszek, Michal},
doi = {10.1007/s11079-015-9386-4},
issn = {1573708X},
journal = {Open Economies Review},
keywords = {Exchange rate forecasting,Half-life,Purchasing power parity},
title = {{Real Exchange Rate Forecasting and PPP: This Time the Random Walk Loses}},
year = {2016}
}
@article{Kurkova1992,
abstract = {Taking advantage of techniques developed by Kolmogorov, we give a direct proof of the universal approximation capabilities of perceptron type networks with two hidden layers. From our proof, we derive estimates of numbers of hidden units based on properties of the function being approximated and the accuracy of its approximation. {\textcopyright} 1992.},
author = {Kůrkov{\'{a}}, V{\v{e}}ra},
doi = {10.1016/0893-6080(92)90012-8},
issn = {08936080},
journal = {Neural Networks},
keywords = {Approximations of continuous functions,Estimates of number of hidden units,Feedforward neural networks,Modulus of continuity,Multilayer perceptron type networks,Sigmoidal activation function,Uniform approximation,Universal approximation capabilities},
title = {{Kolmogorov's theorem and multilayer neural networks}},
year = {1992}
}
@article{Patel2015,
abstract = {This paper addresses problem of predicting direction of movement of stock and stock price index for Indian stock markets. The study compares four prediction models, Artificial Neural Network (ANN), Support Vector Machine (SVM), random forest and naive-Bayes with two approaches for input to these models. The first approach for input data involves computation of ten technical parameters using stock trading data (open, high, low {\&} close prices) while the second approach focuses on representing these technical parameters as trend deterministic data. Accuracy of each of the prediction models for each of the two input approaches is evaluated. Evaluation is carried out on 10 years of historical data from 2003 to 2012 of two stocks namely Reliance Industries and Infosys Ltd. and two stock price indices CNX Nifty and S{\&}P Bombay Stock Exchange (BSE) Sensex. The experimental results suggest that for the first approach of input data where ten technical parameters are represented as continuous values, random forest outperforms other three prediction models on overall performance. Experimental results also show that the performance of all the prediction models improve when these technical parameters are represented as trend deterministic data. {\textcopyright} 2014 Elsevier Ltd. All rights reserved.},
author = {Patel, Jigar and Shah, Sahil and Thakkar, Priyank and Kotecha, K.},
doi = {10.1016/j.eswa.2014.07.040},
isbn = {09574174},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Artificial neural networks,Naive-Bayes classification,Random forest,Stock market,Support vector machine},
title = {{Predicting stock and stock price index movement using Trend Deterministic Data Preparation and machine learning techniques}},
year = {2015}
}
@inproceedings{Wang2014,
abstract = {Due to the complexity of financial market, it is a challenging task to forecast the direction of stock index movement. An accurate prediction of stock index movement may not only provide reference value for the investors to make effective strategy, but also for policy maker to monitor stock market, especially in the emerging market, such as China. In this paper, we investigate the predictability of Least Square Support Vector Machine (LSSVM) by predicting the daily movement direction of China Security Index 300 (CSI 300). For comparing purpose, another artificial intelligence (AI) model, Probabilistic Neural Network (PNN) and two Discriminant Analysis models are performed. Ten technical indicators are selected as input variables of the models. Experimental results reveal that LSSVM method is very promising for directional forecasting for that it outperforms PNN, Linear Discriminant Analysis (LDA), Quadratic Discriminant Analysis (QDA) in both training accuracy and testing accuracy. {\textcopyright} 2014 Published by Elsevier B.V.},
author = {Wang, Shuai and Shang, Wei},
booktitle = {Procedia Computer Science},
doi = {10.1016/j.procs.2014.05.338},
issn = {18770509},
keywords = {Directional prediction,Least squares support vector machine,Probabilistic Neural Network},
title = {{Forecasting direction of China security index 300 movement with least squares support vector machine}},
year = {2014}
}
@article{Rehman2014,
abstract = {Feedback in Neuro-Evolution is explored and evaluated for its application in devising prediction models for foreign currency exchange rates. A novel approach to foreign currency exchange rates forecasting based on Recurrent Neuro-Evolution is introduced. Cartesian Genetic Programming (CGP) is the algorithm deployed for the forecasting model. Recurrent Cartesian Genetic Programming evolved Artificial Neural Network (RCGPANN) is demonstrated to produce computationally efficient and accurate model for forex prediction with an accuracy of as high as 98.872{\%} for a period of 1000 days. The approach utilizes the trends that are being followed in historical data to predict five currency rates against Australian dollar. The model is evaluated using statistical metrics and compared. The computational method outperforms the other methods particularly due to its capability to select the best possible feature in real time and the flexibility that the system provides in feature selection, connectivity pattern and network.},
author = {Rehman, Mehreen and Khan, Gul Muhammad and Mahmud, Sahibzada Ali},
doi = {10.1016/j.ieri.2014.09.083},
issn = {22126678},
journal = {IERI Procedia},
title = {{Foreign Currency Exchange Rates Prediction Using CGP and Recurrent Neural Network}},
year = {2014}
}
@article{Hassan2016,
abstract = {The Penn–Balassa–Samuelson effect is the stylized fact about the positive correlation between cross-country price level and per-capita income. This paper provides evidence that the price–income relation is actually non-linear and turns negative among low income countries. The result is robust along both cross-section and panel dimensions. Additional robustness checks show that biases in PPP estimation and measurement error in low-income countries do not drive the result. Rather, the different stage of development between countries can explain this new finding. The paper shows that a model linking the price level to the process of structural transformation captures the non-monotonic pattern of the data. This provides additional understanding of real exchange rate determinants in developing countries.},
author = {Hassan, Fadi},
doi = {10.1016/j.jinteco.2016.07.009},
issn = {18730353},
journal = {Journal of International Economics},
keywords = {Balassa–Samuelson hypothesis,Developing countries,Penn effect,Real exchange rate,Structural transformation},
title = {{The price of development: The Penn–Balassa–Samuelson effect revisited}},
year = {2016}
}
@article{Stock2002,
abstract = {This article considers forecasting a single time series when there are many predictors (N) and time series observations (T). When the data follow an approximate factor model, the predictors can be summarized by a small number of indexes, which we estimate using principal components. Feasible forecasts are shown to be asymptotically efficient in the sense that the difference between the feasible forecasts and the infeasible forecasts constructed using the actual values of the factors converges in probability to 0 as both N and T grow large. The estimated factors are shown to be consistent, even in the presence of time variation in the factor model.},
author = {Stock, James H. and Watson, Mark W.},
doi = {10.1198/016214502388618960},
issn = {01621459},
journal = {Journal of the American Statistical Association},
keywords = {Factor models,Forecasting,Principal components},
title = {{Forecasting using principal components from a large number of predictors}},
year = {2002}
}
@article{Lebaron1994,
abstract = {Both academic and applied researchers studying financial markets and other economic series have become interested in the topic of chaotic dynamics. The possibility of chaos in financial markets opens important questions for both economic theorists as well as financial market participants. This paper will clarify the empirical evidence for chaos in financial markets and macroeconomic series emphasizing what exactly is known about these time series in terms of forecastability and chaos. We also compare these two concepts from a financial market perspective contrasting the objectives of the practitioner with those of the economic researchers. Finally, we will speculate on the impact of chaos and nonlinear modelling on future economic research.},
author = {Lebaron, Blake},
doi = {10.1098/rsta.1994.0099},
isbn = {0962-8428},
issn = {1364-503X},
journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
title = {{Chaos and Nonlinear Forecastability in Economics and Finance}},
year = {1994}
}
@article{Gunduz2017,
abstract = {Stock market price data have non-linear, noisy and non-stationary structure, and therefore prediction of the price or its direction are both challenging tasks. In this paper, we propose a Convolutional Neural Network (CNN) architecture with a specifically ordered feature set to predict the intraday direction of Borsa Istanbul 100 stocks. Feature set is extracted using different indicators, price and temporal information. Correlations between instances and features are utilized to order the features before they are presented as inputs to the CNN. The proposed classifier is compared with a CNN trained with randomly ordered features and Logistic Regression. Experimental results show that the proposed classifier outperforms both Logistic Regression and CNN that utilizes randomly ordered features. Feature selection methods are also utilized to reduce training time and model complexity.},
author = {Gunduz, Hakan and Yaslan, Yusuf and Cataltepe, Zehra},
doi = {10.1016/j.knosys.2017.09.023},
issn = {09507051},
journal = {Knowledge-Based Systems},
keywords = {Borsa Istanbul,CNN,Convolutional neural networks,Deep learning,Feature correlations,Feature selection,Stock market prediction},
pages = {138--148},
title = {{Intraday prediction of Borsa Istanbul using convolutional neural networks and feature correlations}},
volume = {137},
year = {2017}
}
@article{Rime2010,
abstract = {This paper adds to the research efforts that aim to bridge the divide between macro and micro approaches to exchange rate economics by examining the linkages between exchange rate movements, order flow and expectations of macroeconomic variables. The basic hypothesis tested is that if order flow reflects heterogeneous expectations about macroeconomic fundamentals, and currency markets learn about the state of the economy gradually, then order flow can have both explanatory and forecasting power for exchange rates. Using one year of high frequency data collected via a live feed from Reuters for three major exchange rates, we find that: i) order flow is intimately related to a broad set of current and expected macroeconomic fundamentals; ii) more importantly, order flow is a powerful predictor of daily movements in exchange rates in an out-of-sample exercise, on the basis of economic value criteria such as Sharpe ratios and performance fees implied by utility calculations. {\textcopyright} 2009 Elsevier B.V. All rights reserved.},
author = {Rime, Dagfinn and Sarno, Lucio and Sojli, Elvira},
doi = {10.1016/j.jinteco.2009.03.005},
issn = {00221996},
journal = {Journal of International Economics},
keywords = {Exchange rates,Forecasting,Macroeconomic news,Microstructure,Order flow},
title = {{Exchange rate forecasting, order flow and macroeconomic information}},
year = {2010}
}
@inproceedings{Kamruzzaman2004,
abstract = {Support vector machine (SVM) has appeared as a powerful tool for forecasting forex market and demonstrated better performance over other methods, e.g., neural network or ARIMA based model. SVM-based forecasting model necessitates the selection of appropriate kernel function and values of free parameters: regularization parameter and {\&}949;-insensitive loss function. We investigate the effect of different kernel functions, namely, linear, polynomial, radial basis and spline on prediction error measured by several widely used performance metrics. The effect of regularization parameter is also studied. The prediction of six different foreign currency exchange rates against Australian dollar has been performed and analyzed. Some interesting results are presented.},
author = {Kamruzzaman, J. and Sarker, R.A. and Ahmad, I.},
doi = {10.1109/icdm.2003.1250976},
title = {{SVM based models for predicting foreign currency exchange rates}},
year = {2004}
}
@article{Ganganwar1993,
abstract = {Unbalanced data set, a problem often found in real world application, can cause seriously negative effect on classification performance of machine learning algorithms. There have been many attempts at dealing with classification of unbalanced data sets. In this paper we present a brief review of existing solutions to the class-imbalance problem proposed both at the data and algorithmic levels. Even though a common practice to handle the problem of imbalanced data is to rebalance them artificially by oversampling and/or under-sampling, some researchers proved that modified support vector machine, rough set based minority class oriented rule learning methods, cost sensitive classifier perform good on imbalanced data set. We observed that current research in imbalance data problem is moving to hybrid algorithms.},
author = {Ganganwar, Vaishali},
isbn = {0038-3619},
issn = {2250-2459},
journal = {Southeast Asian Journal of Tropical Medicine and Public Health},
keywords = {*amphotericin B/dt [Drug Therapy],*cryptococcosis/dt [Drug Therapy],*meningitis/dt [Drug Therapy],Adult,Brain Diseases/*microbiology,Brain/microbiology,Cryptococcal/*microbiology,Cryptococcosis/*microbiology,Cryptococcus neoformans,Female,Humans,Male,Meningitis,Middle Aged,Tomography,X-Ray Computed,adult,aged,article,clinical article,computer assisted tomography,female,flucytosine/dt [Drug Therapy],human,itraconazole/dt [Drug Therapy],male,mortality},
pmid = {8362315},
title = {{An overview of classification algorithms for imbalanced datasets}},
year = {1993}
}
@book{McKinney1976,
abstract = {Python for Data Analysis is concerned with the nuts and bolts of manipulating, processing, cleaning, and crunching data in Python. It is also a practical, modern introduction to scientific computing in Python, tailored for data-intensive applications. This is a book about the parts of the Python language and libraries you'll need to effectively solve a broad set of data analysis problems. This book is not an exposition on analytical methods using Python as the implementation language. Written by Wes McKinney, the main author of the pandas library, this hands-on book is packed with practical cases studies. It's ideal for analysts new to Python and for Python programmers new to scientific computing. Use the IPython interactive shell as your primary development environment Learn basic and advanced NumPy (Numerical Python) features Get started with data analysis tools in the pandas library Use high-performance tools to load, clean, transform, merge, and reshape data Create scatter plots and static or interactive visualizations with matplotlib Apply the pandas groupby facility to slice, dice, and summarize datasets Measure data by points in time, whether it's specific instances, fixed periods, or intervals Learn how to solve problems in web analytics, social sciences, finance, and economics, through detailed examples},
author = {McKinney, Wes},
booktitle = {O'Reilly Media, Inc.},
title = {{Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython}},
year = {1976}
}
@article{Tenti1996,
abstract = {This article proposes the use of recurrent neural networks in order to forecast foreign exchange rates. Artificial neural networks have proven to be efficient and profitable in fore casting financial time series. In particular, recurrent networks in which activity patterns pass through the network more than once before they generate an output pattern can learn ex tremely complex temporal sequences. Three recurrent architectures are compared in terms of prediction accuracy of futures forecast for Deutsche mark currency. A trading strategy is then devised and optimized. The profitability of the trading strategy taking into account trans action costs is shown for the different architectures. The methods described here which have obtained promising results in real time trading are applicable to other markets.$\backslash$nThis article proposes the use of recurrent neural networks in order to forecast foreign exchange rates. Artificial neural networks have proven to be efficient and profitable in fore casting financial time series. In particular, recurrent networks in which activity patterns pass through the network more than once before they generate an output pattern can learn ex tremely complex temporal sequences. Three recurrent architectures are compared in terms of prediction accuracy of futures forecast for Deutsche mark currency. A trading strategy is then devised and optimized. The profitability of the trading strategy taking into account trans action costs is shown for the different architectures. The methods described here which have obtained promising results in real time trading are applicable to other markets.},
author = {Tenti, Paolo},
doi = {10.1080/088395196118434},
issn = {10876545},
journal = {Applied Artificial Intelligence},
title = {{Forecasting foreign exchange rates using recurrent neural networks}},
year = {1996}
}
@incollection{Podgorelec2015,
abstract = {Decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the item's target value. It is one of the predictive modelling approaches used in statistics, data mining and machine learning. More descriptive names for such tree models are classification trees or regression trees. In these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels.},
author = {Podgorelec, Vili and Zorman, Milan},
booktitle = {Encyclopedia of Complexity and Systems Science},
doi = {10.1007/978-3-642-27737-5_117-2},
title = {{Decision Tree Learning}},
year = {2015}
}
@article{Menkhoff2012,
abstract = {We provide a broad empirical investigation of momentum strategies in the foreign exchange market. We find a significant cross-sectional spread in excess returns of up to 10{\%} per annum (p.a.) between past winner and loser currencies. This spread in excess returns is not explained by traditional risk factors, it is partially explained by transaction costs and shows behavior consistent with investor under- and overreaction. Moreover, cross-sectional currency momentum has very different properties from the widely studied carry trade and is not highly correlated with returns of benchmark technical trading rules. However, there seem to be very effective limits to arbitrage that prevent momentum returns from being easily exploitable in currency markets. {\textcopyright} 2012 Elsevier B.V.},
author = {Menkhoff, Lukas and Sarno, Lucio and Schmeling, Maik and Schrimpf, Andreas},
doi = {10.1016/j.jfineco.2012.06.009},
issn = {0304405X},
journal = {Journal of Financial Economics},
keywords = {Carry trades,Idiosyncratic volatility,Limits to arbitrage,Momentum returns},
title = {{Currency momentum strategies}},
year = {2012}
}
@book{Wood2015,
abstract = {Python and Matplotlib Essentials for Scientists and Engineers is intended to provide a starting point for scientists or engineers (or students of either discipline) who want to explore using Python and Matplotlib to work with data and/or simulations, and to make publication-quality plots. The active user base of Python and Matplotlib has been growing rapidly in recent years as people realize these packages have a very high level of functionality, are freely available for any likely operating system and are relatively simple to learn and use compared to similar software solutions. No previous programming experience is needed before beginning this book, as my aim is to make this a stand-alone introduction to Python and Matplotlib. Indeed, my hope is that you the reader can take this introduction and discover for yourself in just a few hours whether Python and Matplotlib provide most if not all of the tools you need to get your work done and your publication-quality plots rendered. The examples given in this book are available for download at the companion website pythonessentials.com.},
author = {Wood, Matt A},
booktitle = {Python and Matplotlib Essentials for Scientists and Engineers},
doi = {10.1088/978-1-6270-5620-5},
title = {{Python and Matplotlib Essentials for Scientists and Engineers}},
year = {2015}
}
@article{Yoshihara2014,
abstract = {Investors make decisions based on various factors, including consumer price index, price-earnings ratio, and also miscellaneous events reported by newspapers. In order to assist their decisions in a timely manner, many studies have been conducted to automatically analyze those information sources in the last decades. However, the majority of the efforts was made for utilizing numerical information, partly due to the difficulty to process natural language texts and to make sense of their temporal properties. This study sheds light on this problem by using deep learning, which has been attracting much attention in various areas of research including pattern mining and machine learning for its ability to automatically construct useful features from a large amount of data. Specifically, this study proposes an approach to market trend prediction based on a recurrent deep neural network to model temporal effects of past events. The validity of the proposed approach is demonstrated on the real-world data for ten Nikkei companies.},
author = {Yoshihara, Akira and Fujikawa, Kazuki and Seki, Kazuhiro and Uehara, Kuniaki},
doi = {10.1007/978-3-319-13560-1},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
title = {{Predicting stock market trends by recurrent deep neural networks}},
year = {2014}
}
@article{Taleb2007,
abstract = {TBS is meant to provide a roadmap for dealing with tail events by exposing areas where our knowledge can be deemed fragile, and where tail events can have extreme impacts. It presents methods to avoid such events by not venturing into areas where our knowledge is not rigorous. In other words, it offers away to live safely in aworldwe do not quite understand. It does not get into the trap of offering another precise model to replace another precise model; rather it tells you where we should have the courage to say “I don't know,” or “I know less.”},
author = {Taleb, Nassim Nicholas},
doi = {10.1198/000313007X219996},
issn = {00031305},
journal = {American Statistician},
title = {{Black Swans and the domains of statistics}},
year = {2007}
}
@article{Tyralis2017,
abstract = {Time series forecasting using machine learning algorithms has gained popularity recently. Random forest is a machine learning algorithm implemented in time series forecasting; however, most of its forecasting properties have remained unexplored. Here we focus on assessing the performance of random forests in one-step forecasting using two large datasets of short time series with the aim to suggest an optimal set of predictor variables. Furthermore, we compare its performance to benchmarking methods. The first dataset is composed by 16,000 simulated time series from a variety of Autoregressive Fractionally Integrated Moving Average (ARFIMA) models. The second dataset consists of 135 mean annual temperature time series. The highest predictive performance of RF is observed when using a low number of recent lagged predictor variables. This outcome could be useful in relevant future applications, with the prospect to achieve higher predictive accuracy.},
author = {Tyralis, Hristos and Papacharalampous, Georgia},
doi = {10.3390/a10040114},
issn = {19994893},
journal = {Algorithms},
keywords = {ARFIMA,ARMA,Machine learning,One-step ahead forecasting,Random forests,Time series forecasting,Variable selection},
title = {{Variable selection in time series forecasting using random forests}},
year = {2017}
}
@article{Tobergte2013,
abstract = {A practical tutorial that guarantees fast, accurate, and easy-to-code solutions to your numerical and scientific computing problems with the power of SciPy and Python},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Tobergte, David R. and Curtis, Shirley},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
isbn = {9788578110796},
issn = {1098-6596},
journal = {Journal of Chemical Information and Modeling},
keywords = {icle},
pmid = {25246403},
title = {{Learning SciPy for Numerical and Scientific Computing Second Edition}},
year = {2013}
}
@article{Rogoff1996,
abstract = {FIRST ARTICULATED by scholars of the ISalamanca school in sixteenth century Spain, purchasing power parity (PPP) is the disarmingly simple empirical proposition that, once converted to a common currency, national price levels should be equal. The basic idea is that if goods market arbitrage enforces broad parity in prices across a sufficient range of individual goods (the law of one price), then there should also be a high correlation in aggregate price levels. While few empirically literate econo- mists take PPP seriously as a short-term proposition, most instinctively believe in some variant of purchasing power parity as an anchor for long-run real exchange rates. Warm, fuzzy feelings about PPP are not, of course, a substitute for hard evidence.},
author = {Rogoff, Kenneth},
journal = {Journal of Economic Literature},
keywords = {Price Convergence},
title = {{The Purchasing Power Parity Puzzle}},
year = {1996}
}
@article{Hochreiter1997,
abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient-based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O(1). Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
author = {Hochreiter, Sepp and Schmidhuber, J{\"{u}}rgen},
doi = {10.1162/neco.1997.9.8.1735},
issn = {08997667},
journal = {Neural Computation},
title = {{Long Short-Term Memory}},
year = {1997}
}
@inproceedings{Gold2003,
abstract = {This study investigates high frequency currency trading with neural networks trained via Recurrent Reinforcement Learning (RRL). We compare the performance of single layer networks with networks having a hidden layer, and examine the impact of the fixed system parameters on performance. In general, we conclude that the trading systems may be effective, but the performance varies widely for different currency markets and this variability cannot be explained by simple statistics of the markets. Also we find that the single layer network outperforms the two layer network in this application.},
author = {Gold, C.},
booktitle = {IEEE/IAFE Conference on Computational Intelligence for Financial Engineering, Proceedings (CIFEr)},
doi = {10.1109/CIFER.2003.1196283},
isbn = {0780376544},
keywords = {Computer networks,Frequency,Gold,History,Learning,Neural networks,Neurons,Recurrent neural networks,Statistics,System testing},
title = {{FX trading via recurrent reinforcement learning}},
year = {2003}
}
@article{Hsu2009,
abstract = {Stock price prediction has attracted much attention from both practitioners and researchers. However, most studies in this area ignored the non-stationary nature of stock price series. That is, stock price series do not exhibit identical statistical properties at each point of time. As a result, the relationships between stock price series and their predictors are quite dynamic. It is challenging for any single artificial technique to effectively address this problematic characteristics in stock price series. One potential solution is to hybridize different artificial techniques. Towards this end, this study employs a two-stage architecture for better stock price prediction. Specifically, the self-organizing map (SOM) is first used to decompose the whole input space into regions where data points with similar statistical distributions are grouped together, so as to contain and capture the non-stationary property of financial series. After decomposing heterogeneous data points into several homogenous regions, support vector regression (SVR) is applied to forecast financial indices. The proposed technique is empirically tested using stock price series from seven major financial markets. The results show that the performance of stock price prediction can be significantly enhanced by using the two-stage architecture in comparison with a single SVR model. {\textcopyright} 2008 Elsevier Ltd. All rights reserved.},
author = {Hsu, Sheng Hsun and Hsieh, JJ Po An and Chih, Ting Chih and Hsu, Kuei Chu},
doi = {10.1016/j.eswa.2008.10.065},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Self-organizing map,Stock price prediction,Support vector machine},
title = {{A two-stage architecture for stock price forecasting by integrating self-organizing map and support vector regression}},
year = {2009}
}
@article{Bartram2019,
abstract = {Using real-time data, currency anomalies are profitable during in-sample and out-of-sample periods , both before and after transaction costs, but trading profits decrease substantially after the publication of the underlying academic research. The decline is greater for anomalies with larger in-sample profits and lower arbitrage costs, and signal ranks and performance decay quickly, suggesting that currency anomalies reflect mispricing rather than compensation for risk or statistical bias. Mispricing is systematically related to mistakes and changes in analysts' currency forecasts. In particular, analysts expect anomaly payoffs that are too low compared with actual anomaly profits. However, analysts update their forecasts to incorporate lagged anomaly information, and their mistakes become smaller after publication. Trading profits from mispricing only exceed those based on analysts' forecasts before anomaly publication, since mispricing profits are insignificant post publication. These results are consistent with a behavioral explanation for currency anomalies. Abstract Using real-time data, currency anomalies are profitable during in-sample and out-of-sample periods , both before and after transaction costs, but trading profits decrease substantially after the publication of the underlying academic research. The decline is greater for anomalies with larger in-sample profits and lower arbitrage costs, and signal ranks and performance decay quickly, suggesting that currency anomalies reflect mispricing rather than compensation for risk or statistical bias. Mispricing is systematically related to mistakes and changes in analysts' currency forecasts. In particular, analysts expect anomaly payoffs that are too low compared with actual anomaly profits. However, analysts update their forecasts to incorporate lagged anomaly information, and their mistakes become smaller after publication. Trading profits from mispricing only exceed those based on analysts' forecasts before anomaly publication, since mispricing profits are insignificant post publication. These results are consistent with a behavioral explanation for currency anomalies.},
author = {Bartram, S{\"{o}}hnke M. and Djuranovik, Leslie and Garratt, Anthony},
doi = {10.2139/ssrn.3222252},
journal = {SSRN Electronic Journal},
title = {{Currency Anomalies}},
year = {2019}
}
@article{VanDerWalt2011,
abstract = {In the Python world, NumPy arrays are the standard representation for numerical data. Here, we show how these arrays enable efficient implementation of numerical computations in a high-level language. Overall, three techniques are applied to improve performance: vectorizing calculations, avoiding copying data in memory, and minimizing operation counts. We first present the NumPy array structure, then show how to use it for efficient computation, and finally how to share array data with other libraries.},
author = {{Van Der Walt}, St{\'{e}}fan and Colbert, S. Chris and Varoquaux, Ga{\"{e}}l},
doi = {10.1109/MCSE.2011.37},
issn = {15219615},
journal = {Computing in Science and Engineering},
keywords = {NumPy,Python,numerical computations,programming libraries,scientific programming},
title = {{The NumPy array: A structure for efficient numerical computation}},
year = {2011}
}
@article{Abreu2018,
abstract = {Technical analysis is used to discover investment opportunities. To test this hypothesis we propose an hybrid system using machine learning techniques together with genetic algorithms. Using technical analysis there are more ways to represent a currency exchange time series than the ones it is possible to test computationally, i.e., it is unfeasible to search the whole input feature space thus a genetic algorithm is an alternative. In this work, an architecture for automatic feature selection is proposed to optimize the cross validated performance estimation of a Naive Bayes model using a genetic algorithm. The proposed architecture improves the return on investment of the unoptimized system from 0,43{\%} to 10,29{\%} in the validation set. The features selected and the model decision boundary are visualized using the algorithm t-Distributed Stochastic Neighbor embedding.},
archivePrefix = {arXiv},
arxivId = {1805.11232},
author = {Abreu, Gon{\c{c}}alo and Neves, Rui and Horta, Nuno},
eprint = {1805.11232},
title = {{Currency exchange prediction using machine learning, genetic algorithms and technical analysis}},
url = {http://arxiv.org/abs/1805.11232},
year = {2018}
}
@article{Wang2013,
abstract = {The prediction of a stock market direction may serve as an early recommendation system for short-term investors and as an early financial distress warning system for long-term shareholders. In this paper, we propose an empirical study on the Korean and Hong Kong stock market with an integrated machine learning framework that employs Principal Component Analysis (PCA) and Support Vector Machine (SVM). We try to predict the upward or downward direction of stock market index and stock price. In the proposed framework, PCA, as a feature selection method, identifies principal components in the stock market movement and SVM, as a classifier for future stock market movement, processes them along with other economic factors in training and forecasting. We present the results of an extensive empirical study of the proposed method on the Korean composite stock price index (KOSPI) and Hangseng index (HSI), as well as the individual constituents included in the indices. In our experiment, ten years data (from January 1st, 2002 to January 1st, 2012) are collected and schemed by rolling windows to predict one-day-ahead directions. The experimental results show notably high hit ratios in predicting the movements of the individual constituents in the KOSPI and HSI. The results also varify the $\backslash$textit{\{}co-movement{\}} effect between the Korean (Hong Kong) stock market and the American stock market.},
archivePrefix = {arXiv},
arxivId = {arXiv:1309.7119v1},
author = {Wang, Yanshan and Choi, Ic},
eprint = {arXiv:1309.7119v1},
journal = {arXiv preprint arXiv:1309.7119},
keywords = {hsi,kospi,pca,principal component analysis,stock direction prediction,support vector machine,svm},
title = {{Market Index and Stock Price Direction Prediction using Machine Learning Techniques: An empirical study on the KOSPI and HSI}},
year = {2013}
}
@article{Filippou2017,
abstract = {We study the role of domestic and global factors in the payoffs of portfolios mimicking carry, dollar-carry, and momentum strategies. Using factors summarizing large data sets of macroeconomic and financial variables, we find that global equity-market factors are predictive for carry-trade returns, whereas U.S. inflation and consumption variables drive dollar-carry-trade payoffs, momentum returns are predominantly driven by U.S. inflation factors, and global factors capture the countercyclical nature of currency premia. We also find predictability in the exchange-rate component of each strategy and demonstrate strong economic value for risk-averse investors with mean-variance preferences, regardless of base currency.},
author = {Filippou, Ilias and Taylor, Mark P.},
doi = {10.1017/s0022109017000424},
issn = {0022-1090},
journal = {Journal of Financial and Quantitative Analysis},
title = {{Common Macro Factors and Currency Premia}},
year = {2017}
}
@inproceedings{Gui2015,
abstract = {Support vector machines (SVMs) are promising methods for the prediction of financial time-series because they use a risk function consisting of the empirical error and a regularized term which is derived from the structural risk minimization principle. This study applies SVM to predicting the stock price index. In addition, this study examines the feasibility of applying SVM in financial forecasting by comparing it with back-propagation neural networks and case-based reasoning. The experimental results show that SVM provides a promising alternative to stock market prediction. {\textcopyright} 2003 Elsevier B.V. All rights reserved.},
author = {Gui, Bin and Wei, Xianghe and Shen, Qiong and Qi, Jingshan and Guo, Liqiang},
booktitle = {Proceedings - 2014 10th International Conference on Computational Intelligence and Security, CIS 2014},
doi = {10.1109/CIS.2014.22},
isbn = {9781479974344},
keywords = {Financial time series,Information granulation,Regression,Support vector machine},
title = {{Financial time series forecasting using support vector machine}},
year = {2015}
}
@article{Glattfelder2011,
abstract = {We have discovered 12 independent new empirical scaling laws in foreign exchange data-series that hold for close to three orders of magnitude and across 13 currency exchange rates. Our statistical analysis crucially depends on an event-based approach that measures the relationship between different types of events. The scaling laws give an accurate estimation of the length of the price-curve coastline, which turns out to be surprisingly long. The new laws substantially extend the catalogue of stylised facts and sharply constrain the space of possible theoretical explanations of the market mechanisms.},
author = {Glattfelder, J. B. and Dupuis, A. and Olsen, R. B.},
doi = {10.1080/14697688.2010.481632},
issn = {14697688},
journal = {Quantitative Finance},
keywords = {Empirical time series analysis,Financial time series,Foreign exchange markets,Power laws},
title = {{Patterns in high-frequency FX data: Discovery of 12 empirical scaling laws}},
year = {2011}
}
@article{Ozturk2016,
abstract = {Technical indicators are widely used in Forex and other financial markets which are the building blocks of many trading systems. A trading system is based on technical indicators or pattern-based approaches which produces buy/sell signals to trade in the market. In this paper, a heuristic based trading system on Forex data, which is developed using popular technical indicators is presented. The system grounds on selecting and combining the trading rules based on indicators using heuristic methods. The selection of the trading rules is realized by using Genetic algorithm and a greedy search heuristic. A weighted majority voting method is proposed to combine the technical indicator based trading rules to form a single trading rule. The experiments are conducted on 2 major currency pairs in 3 different time frames where promising results are achieved.},
author = {Ozturk, Murat and Toroslu, Ismail Hakki and Fidan, Guven},
doi = {10.1016/j.asoc.2016.01.048},
issn = {15684946},
journal = {Applied Soft Computing Journal},
keywords = {Forex,Genetic algorithm,Heuristic methods,Technical analysis,Technical indicator,Trading rule,Trading system},
title = {{Heuristic based trading system on Forex data using technical indicator rules}},
year = {2016}
}
@inproceedings{Song2010,
abstract = {Principal component analysis (PCA) has been widely applied in the area of computer science. It is well-known that PCA is a popular transform method and the transform result is not directly related to a sole feature component of the original sample. However, in this paper, we try to apply principal components analysis (PCA) to feature selection. The proposed method well addresses the feature selection issue, from a viewpoint of numerical analysis. The analysis clearly shows that PCA has the potential to perform feature selection and is able to select a number of important individuals from all the feature components. Our method assumes that different feature components of original samples have different effects on feature extraction result and exploits the eigenvectors of the covariance matrix of PCA to evaluate the significance of each feature component of the original sample. When evaluating the significance of the feature components, the proposed method takes a number of eigenvectors into account. Then it uses a reasonable scheme to perform feature selection. The devised algorithm is not only subject to the nature of PCA but also computationally efficient. The experimental results on face recognition show that when the proposed method is able to greatly reduce the dimensionality of the original samples, it also does not bring the decrease in the recognition accuracy.},
author = {Song, Fengxi and Guo, Zhongwei and Mei, Dayong},
booktitle = {Proceedings - 2010 International Conference on System Science, Engineering Design and Manufacturing Informatization, ICSEM 2010},
doi = {10.1109/ICSEM.2010.14},
isbn = {9780769542232},
keywords = {Face recognition,Feature selection,Principal component analysis},
title = {{Feature selection using principal component analysis}},
year = {2010}
}
@article{LopezdePrado2018,
abstract = {The rate of failure in quantitative finance is high, and particularly so in financial machine learning. The few managers who succeed amass a large amount of assets, and deliver consistently exceptional performance to their investors. However, that is a rare outcome, for reasons that will become apparent in this article. Over the past two decades, I have seen many faces come and go, firms started and shut down. In my experience, there are ten critical mistakes underlying most of those failures. This paper is partly based on the book Advances in Financial Machine Learning (Wiley, 2018). The first chapter of this book is available at http://ssrn.com/abstract=3104847. A presentation can be found at http://ssrn.com/abstract=3031282.},
author = {{Lopez de Prado}, Marcos},
doi = {10.2139/ssrn.3104816},
isbn = {2122243589},
issn = {1556-5068},
journal = {SSRN},
keywords = {Backtest Overfitting,Big Data,E44,G0,G1,G15,G2,G24,High Performance Computing,Investment Strategies,Machine Learning,Quantamental Investing},
title = {{The 10 Reasons Most Machine Learning Funds Fail}},
year = {2018}
}
@article{Malkiel1973,
abstract = {"Bluntly state, the careful estimates of security analysts . . . do little, if any, better than those that would be obtained by simple extrapolation of past trends . . (p. 150).},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Malkiel, B.G.},
doi = {10.1111/1467-6419.00091},
eprint = {arXiv:1011.1669v3},
isbn = {0393047814},
issn = {09500804},
journal = {Foundations},
pmid = {25246403},
title = {{A Random Walk Down Wall Street}},
year = {1973}
}
@article{Mclean2016,
abstract = {We study the out-of-sample and post-publication return-predictability of 97 variables that academic studies show to predict cross-sectional stock returns. Portfolio returns are 26{\%} lower out-of-sample and 58{\%} lower post-publication. The out-of-sample decline is an upper bound estimate of data mining effects. We estimate a 32{\%} (58{\%} - 26{\%}) lower return from publication-informed trading. Post-publication declines are greater for predictors with higher in-sample returns, and returns are higher for portfolios concentrated in stocks with high idiosyncratic risk and low liquidity. Predictor portfolios exhibit post-publication increases in correlations with other published-predictor portfolios. Our findings suggest investors learn about mispricing from academic publications.},
author = {Mclean, R. David and Pontiff, Jeffrey},
doi = {10.1111/jofi.12365},
issn = {15406261},
journal = {Journal of Finance},
title = {{Does Academic Research Destroy Stock Return Predictability?}},
year = {2016}
}
@article{Bailey2011,
abstract = {We evaluate the probability that an estimated Sharpe ratio exceeds a given threshold in presence of non-Normal returns. We show that this new uncertainty-adjusted investment skill metric (called Probabilistic Sharpe ratio, or PSR) has a number of important applications: First, it allows us to establish the track record length needed for rejecting the hypothesis that a measured Sharpe ratio is below a certain threshold with a given confidence level. Second, it models the trade-off between track record length and undesirable statistical features (e.g., negative skewness with positive excess kurtosis). Third, it explains why track records with those undesirable traits would benefit from reporting performance with the highest sampling frequency such that the IID assumption is not violated. Fourth, it permits the computation of what we call the Sharpe ratio Efficient Frontier (SEF), which lets us optimize a portfolio under non-Normal, leveraged returns while incorporating the uncertainty derived from track record length. Results can be validated using the Python code in the Appendix.},
author = {Bailey, David H. and {Lopez de Prado}, Marcos},
doi = {10.2139/ssrn.1821643},
issn = {14651211},
journal = {SSRN},
keywords = {C02,D53,Efficient frontier,Excess kurtosis,G11,G14,IID,Normal distribution,Sharpe ratio,Skewness,Track record},
title = {{The Sharpe Ratio Efficient Frontier}},
year = {2011}
}
@inproceedings{MacK2011,
abstract = {The 1959 invention of the planar silicon transistor led to the development of the integrated circuit (IC) and the growth trend in IC complexity known as Moore's Law. While Moore's observation came in 1965, his original trend line showing a doubling of components per chip each year began with one component in 1959. Thus, we have now experienced 50 years of Moore's Law. This paper provides a history of Moore's Law through its many changes and reinterpretations, containing possibly a few new ones as well.},
author = {MacK, Chris A.},
booktitle = {IEEE Transactions on Semiconductor Manufacturing},
doi = {10.1109/TSM.2010.2096437},
issn = {08946507},
keywords = {History,Moore's Law,learning curve},
title = {{Fifty years of Moore's law}},
year = {2011}
}
@article{Camargo2013,
abstract = {Employing a recent technique which allows the representation of nonstationary data by means of a juxtaposition of locally stationary patches of different length, we introduce a comprehensive analysis of the key observables in a financial market: the trading volume and the price fluctuations. From the segmentation procedure we are able to introduce a quantitative description of a group of statistical features (stylizes facts) of the trading volume and price fluctuations, namely the tails of each distribution, the U-shaped profile of the volume in a trading session and the evolution of the trading volume autocorrelation function. The segmentation of the trading volume series provides evidence of slow evolution of the fluctuating parameters of each patch, pointing to the mixing scenario. Assuming that long-term features are the outcome of a statistical mixture of simple local forms, we test and compare different probability density functions to provide the long-term distribution of the trading volume, concluding that the log-normal gives the best agreement with the empirical distribution. Moreover, the segmentation of the magnitude price fluctuations are quite different from the results for the trading volume, indicating that changes in the statistics of price fluctuations occur at a faster scale than in the case of trading volume.},
author = {Camargo, Sabrina and Queir{\'{o}}s, S{\'{i}}lvio M.Duarte and Anteneodo, Celia},
doi = {10.1140/epjb/e2013-30974-9},
issn = {14346028},
journal = {European Physical Journal B},
title = {{Bridging stylized facts in finance and data non-stationarities}},
year = {2013}
}
@unpublished{Dahlquist2015,
abstract = {Past trends in a broad range of fundamental variables predict currency returns. We document that a trading strategy that goes long currencies in countries with strong economic momentum and short currencies in countries with weak economic momentum exhibits an annualized Sharpe ratio close to one and yields a signi cant alpha when controlling for standard carry, momentum, and value strategies. Moreover, the economic momentum strategy subsumes the alpha of carry trades, suggesting that interest rate diff erentials are captured by past economic trends. Finally, we fi nd that investors' expectations of fundamentals relate positively with recent trends in fundamentals across countries and variables.},
author = {Dahlquist, Magnus and Hasseltoft, Henrik},
booktitle = {SSRN},
doi = {10.2139/ssrn.2579666},
keywords = {F31,Foreign exchange rates,G12,G15,predictability,surveys,trend following,trends.},
title = {{Economic Momentum and Currency Returns}},
year = {2015}
}
@inproceedings{Chang2009,
abstract = {Forecasting currency exchange rates is an important issue in finance. This topic has received much attention, particularly in econometrics and financial selection of variables that influence forecasts. In this paper, a new forecasting model is constructed: we adopt a Genetic Algorithm (GA) to provide the optimal variables weight and we select the optimal set of variables as the input layer neurons, and then we predict the exchange rates with the Back Propagation Network (BPN), called the GABPN model. Basically, we expect improved variable selection to provide better forecasting performance than a random method. As a result, our experiments showed that the GABPN obtained the best forecasting performance and was highly consistent with the actual data. Within the selected 27 variables, only 10 variables play critical factors in influencing forecasting performance; moreover, the GABPN method with proper variables even outperformed the case with full variables. In addition, the proposed model provides valuable information in financial analysis by providing the correct variables that most influence exchange rate trends.},
author = {Chang, Jui Fang and Kuan, Chi Ming and Lin, Yu Wen},
booktitle = {IIH-MSP 2009 - 2009 5th International Conference on Intelligent Information Hiding and Multimedia Signal Processing},
doi = {10.1109/IIH-MSP.2009.245},
isbn = {9780769537627},
title = {{Forecasting exchange rates by genetic algorithms based back propagation network model}},
year = {2009}
}
@book{Geron2017,
abstract = {Through a series of recent breakthroughs, deep learning has boosted the entire field of machine learning. Now, even programmers who know close to nothing about this technology can use simple, efficient tools to implement programs capable of learning from data. This practical book shows you how. Using concrete examples, minimal theory, and two production-ready Python frameworks—scikit-learn and TensorFlow—author Aur{\'{e}}lien G{\'{e}}ron helps you gain an intuitive understanding of the concepts and tools for building intelligent systems. You'll learn a range of techniques, starting with simple linear regression and progressing to deep neural networks.},
archivePrefix = {arXiv},
arxivId = {1412.3919},
author = {G{\'{e}}ron, Aur{\'{e}}lien},
booktitle = {Hands-on Machine Learning with Scikit-Learn and TensorFlow},
doi = {10.3389/fninf.2014.00014},
eprint = {1412.3919},
isbn = {9781491962299},
issn = {1662-5196},
pmid = {24600388},
title = {{Hands-On Machine Learning with Scikit-Learn and TensorFlow}},
year = {2017}
}
@article{Larsen2010,
abstract = {Historical stock prices are used to predict the direction of future stock prices. The developed stock price prediction model uses a novel two-layer reasoning approach that employs domain knowledge from technical analysis in the first layer of reasoning to guide a second layer of reasoning based on machine learning. The model is supplemented by a money management strategy that use the historical success of predictions made by the model to determine the amount of capital to invest on future predictions. Based on a number of portfolio simulations with trade signals generated by the model, we conclude that the prediction model successfully outperforms the Oslo Benchmark Index (OSEBX).},
author = {Larsen, Jan Ivar},
doi = {10.1080/00420986820080431},
isbn = {6072552749},
issn = {0042-0980},
journal = {Urban Studies},
title = {{Predicting Stock Prices Using Technical Analysis and Machine Learning}},
year = {2010}
}
@article{Rosenblatt1958,
abstract = {To answer the questions of how information about the physical world is sensed, in what form is information remembered, and how does information retained in memory influence recognition and behavior, a theory is developed for a hypothetical nervous system called a perceptron. The theory serves as a bridge between biophysics and psychology. It is possible to predict learning curves from neurological variables and vice versa. The quantitative statistical approach is fruitful in the understanding of the organization of cognitive systems. 18 references.},
archivePrefix = {arXiv},
arxivId = {arXiv:1112.6209},
author = {Rosenblatt, F.},
doi = {10.1037/h0042519},
eprint = {arXiv:1112.6209},
isbn = {0033-295X},
issn = {0033295X},
journal = {Psychological Review},
keywords = {PERCEPTION, AS INFORMATION STORAGE MODEL INFORMATI},
pmid = {13602029},
title = {{The perceptron: A probabilistic model for information storage and organization in the brain}},
year = {1958}
}
@article{Cortes1995,
abstract = {Oil/water partition coefficient (log P) is one of the key points for lead compound to be drug. In silico log P models based solely on chemical structures have become an important part of modern drug discovery. Here, we report support vector machines, radial basis function neural networks, and multiple linear regression methods to investigate the correlation between partition coefficient and physico-chemical descriptors for a large data set of compounds. The correlation coefficient r (2) between experimental and predicted log P for training and test sets by support vector machines, radial basis function neural networks, and multiple linear regression is 0.92, 0.90, and 0.88, respectively. The results show that non-linear support vector machines derives statistical models that have better prediction ability than those of radial basis function neural networks and multiple linear regression methods. This indicates that support vector machines can be used as an alternative modeling tool for quantitative structure-property/activity relationships studies.},
author = {Cortes, Corinna and Vapnik, Vladimir},
doi = {10.1023/A:1022627411411},
issn = {15730565},
journal = {Machine Learning},
keywords = {efficient learning algorithms,neural networks,pattern recognition,polynomial classifiers,radial basis function classifiers},
title = {{Support-Vector Networks}},
year = {1995}
}
@unpublished{Harvey2014,
abstract = {We provide some new tools to evaluate trading strategies. When it is known that many strategies and combinations of strategies have been tried, we need to adjust our evaluation method for these multiple tests. Sharpe Ratios and other statistics will be overstated. Our methods are simple to implement and allow for the real-time evaluation of candidate trading strategies.  Related papers are: {\textless}a href="http://ssrn.com/abstract=2345489"{\textgreater}Backtesting{\textless}/a{\textgreater} as well as {\textless}a href="http://ssrn.com/abstract=2249314"{\textgreater}... and the Cross-Section of Expected Returns{\textless}/a{\textgreater}.},
author = {Harvey, Campbell R. and Liu, Yan},
booktitle = {SSRN},
doi = {10.2139/ssrn.2474755},
keywords = {B41,BHY,Backtest,Bonferroni,C12,C20,Capital IQ,Data Mining,FDR,FWER,G00,G12,G14,G30,Haircut,Haircut Sharpe Ratio,Higgs Boson,Holm,In-Sample tests,Machine Learning,Multiple tests,Out-of-Sample tests,PBO,Sharpe ratio,Strategy selection,Trading Strategies},
title = {{Evaluating Trading Strategies}},
year = {2014}
}
@article{Rebonato2017,
abstract = {There are many factor strategies—value-growth investing, momentum, and short volatility strategies, to name but a few—that beat the market. To determine which factors that we should choose, factor investing asks: how well can a particular investor weather hard times relative to the average investor? Answering this question helps an investor reap long-run factor premiums by embracing risks that lose money during bad times but make up for it the rest of the time with attractive rewards. When factor investing can be done cheaply, it raises the bar for active management.},
author = {Rebonato, Riccardo},
doi = {10.1080/14697688.2017.1283915},
issn = {1469-7688},
journal = {Quantitative Finance},
title = {{Asset Management: A Systematic Approach to Factor Investing}},
year = {2017}
}
@article{Chatzis2018,
abstract = {This work contributes to this ongoing debate on the nature and the characteristics of propagation channels of crash events in international stock markets. Specifically, we investigate transmission mechanisms across stock markets along with effects from bond and currency markets. Our approach comprises a solid forecasting mechanism of the probability of a stock market crash event in various time frames. The developed approach combines different machine learning algorithms which are presented with daily stock, bond and currency data from 39 countries that cover a large spectrum of economies. Specifically, we leverage the merits of a series of techniques including Classification Trees, Support Vector Machines, Random Forests, Neural Networks, Extreme Gradient Boosting, and Deep Neural Networks. To the best of our knowledge, this is the first time that Deep Learning and Boosting approaches are considered in the literature as a means of predicting stock market crisis episodes. The independent variables included in our data contain information regarding both the two fundamental linkage channels through which financial contagion can be initiated: returns and volatility. We apply a suite of machine learning algorithms for selecting the most relevant variables out of a large set of proposed ones. Finally, we employ bootstrap sampling for adjusting the imbalanced nature of the available fitting dataset. Our experimental results provide strong evidence that stock market crises tend to exhibit persistence. We also find significant evidence of interdependence and cross-contagion effects among stock, bond and currency markets. Finally, we show that the use of Deep Neural Networks significantly increases the classification accuracy, while offering a robust way to create a global systemic early warning tool that is more efficient and risk-sensitive than the currently established ones. Thus, central banks may use these tools to early adjust their monetary policy, so as to ensure financial stability.},
author = {Chatzis, Sotirios P. and Siakoulis, Vassilis and Petropoulos, Anastasios and Stavroulakis, Evangelos and Vlachogiannakis, Nikos},
doi = {10.1016/j.eswa.2018.06.032},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Deep learning,Forecasting,Random forests,Stock market crashes,Support vector machines,XGBoost},
title = {{Forecasting stock market crisis events using deep and statistical machine learning techniques}},
year = {2018}
}
@article{Menkhoff2016,
abstract = {We study the information in order flows in the world's largest over-the-counter market, the foreign exchange market. The analysis draws on a data set covering a broad cross-section of currencies and different customer segments of foreign exchange endusers. The results suggest that order flows are highly informative about future exchange rates and provide significant economic value. We also find that different customer groups can share risk with each other effectively through the intermediation of a large dealer, and differ markedly in their predictive ability, trading styles, and risk exposure.},
author = {Menkhoff, Lukas and Sarno, Lucio and Schmeling, Maik and Schrimpf, Andreas},
doi = {10.1111/jofi.12378},
issn = {15406261},
journal = {Journal of Finance},
title = {{Information Flows in Foreign Exchange Markets: Dissecting Customer Currency Trades}},
year = {2016}
}
@article{Stock2010,
abstract = {Historically, time series forecasts of economic variables have used only a handful of predictor variables, while forecasts based on a large number of predictors have been the province of judgmental forecasts and large structural econometric models. The past decade, however, has seen considerable progress in the development of time series forecasting methods that exploit many predictors, and this chapter surveys these methods. The first group of methods considered is forecast combination (forecast pooling), in which a single forecast is produced from a panel of many forecasts. The second group of methods is based on dynamic factor models, in which the comovements among a large number of economic variables are treated as arising from a small number of unobserved sources, or factors. In a dynamic factor model, estimates of the factors (which become increasingly precise as the number of series increases) can be used to forecast individual economic variables. The third group of methods is Bayesian model averaging, in which the forecasts from very many models, which differ in their constituent variables, are averaged based on the posterior probability assigned to each model. The chapter also discusses empirical Bayes methods, in which the hyperparameters of the priors are estimated. An empirical illustration applies these different methods to the problem of forecasting the growth rate of the U.S. index of industrial production with 130 predictor variables. ?? 2006 Elsevier B.V. All rights reserved.},
author = {Stock, James and Watson, Mark},
journal = {Handbook of economic forecasting},
title = {{Forecasting with Many Predictors}},
year = {2010}
}
@unpublished{Dome2008,
abstract = {I give an overview of the Efficient Markets Hypothesis (EMH) and its discussion in the economic literature. I discuss the classical form of the EMH and the recent shift in the academic approach. Empirical analysis of the BUX and FTSE 100 indices supports theory. In the third chapter I explain the possibilities and limitations of return prediction. I illustrate the breakdown of the OLS show a possible correction using real time return prediction.},
author = {D{\"{o}}me, Botond},
booktitle = {SSRN},
doi = {10.2139/ssrn.756465},
keywords = {Efficient markets hypothesis,G14,real-time forecasting,return predictability},
title = {{Efficiency and Return Predictability}},
year = {2008}
}
@article{Nguyen2018,
abstract = {Prediction of stock price is always an interesting task. However, it is not easy to make this prediction with high accuracy. Recently, plenty of combinations of statistical methods have been proposed. The main direction of these methods is that combination of regression learner (e.g., SVM) and a clustering of data (e.g., SOM). While these methods make relative success, their extensibility is still under discussion. In this paper, we propose an hybrid model of self-organized map and integrated fuzzy rules with support vector machine. The proposition method is evaluated to be a good approach to apply to stock price analysis. Moreover, this method provides interpretable rules which can be understood, calibrated, and modified by experts in order to direct the learning phase. {\textcopyright} Springer Nature Singapore Pte Ltd. 2018.},
author = {Nguyen, Duc Hien and Le, Van Minh},
doi = {10.1007/978-981-10-7512-4_32},
isbn = {9789811075117},
issn = {21945357},
journal = {Advances in Intelligent Systems and Computing},
keywords = {Fuzzy model,Machine learning,Self-organized map,Stock prediction,Support vector machine},
title = {{Hybrid model of self-organized map and integrated fuzzy rules with support vector machine: Application to stock price analysis}},
year = {2018}
}
@article{Lustig2011,
abstract = {We identify a ‘slope' factor in exchange rates. High interest rate currencies load more on this slope factor than low interest rate currencies. This factor accounts for most of the cross-sectional variation in average excess returns between high and low interest rate currencies. A standard, no-arbitrage model of interest rates with two factors – a country-specific factor and a global factor – can replicate these findings, provided there is sufficient heterogeneity in exposure to global or common innovations. We show that our slope factor identifies these common shocks, and we provide empirical evidence that it is related to changes in global equity market volatility. By investing in high interest rate currencies and borrowing in low interest rate currencies, US investors load up on global risk.},
author = {Lustig, Hanno and Roussanov, Nikolai and Verdelhan, Adrien},
doi = {10.1093/rfs/hhr068},
isbn = {08939454},
issn = {08939454},
journal = {Review of Financial Studies},
pmid = {900374550},
title = {{Common risk factors in currency markets}},
year = {2011}
}
@article{Moskowitz2012,
abstract = {We document significant "time series momentum" in equity index, currency, commodity, and bond futures for each of the 58 liquid instruments we consider. We find persistence in returns for one to 12 months that partially reverses over longer horizons, consistent with sentiment theories of initial under-reaction and delayed over-reaction. A diversified portfolio of time series momentum strategies across all asset classes delivers substantial abnormal returns with little exposure to standard asset pricing factors and performs best during extreme markets. Examining the trading activities of speculators and hedgers, we find that speculators profit from time series momentum at the expense of hedgers. {\textcopyright} 2011 Elsevier B.V..},
author = {Moskowitz, Tobias J. and Ooi, Yao Hua and Pedersen, Lasse Heje},
doi = {10.1016/j.jfineco.2011.11.003},
issn = {0304405X},
journal = {Journal of Financial Economics},
keywords = {Asset pricing,Futures pricing,International financial markets,Market efficiency,Trading volume},
title = {{Time series momentum}},
year = {2012}
}
@article{Genuer2012,
abstract = {Random forests, introduced by Leo Breiman in 2001, are a very effective statis- tical method. The complex mechanism of the method makes theoretical anal- ysis difficult. Therefore, simplified versions of random forests, called purely random forests, which can be theoretically handled more easily, have been considered. In this paper we study the variance of such forests. First, we show a general upper bound which emphasizes the fact that a forest reduces the variance. We then introduce a simple variant of purely random forests, that we call purely uniformly random forests. For this variant and in the context of regression problems with a one-dimensional predictor space, we show that both random trees and random forests reach minimax rate of convergence. In addition, we prove that compared to random trees, random forests improve accuracy by reducing the estimator variance by a factor of three fourths.},
author = {Genuer, Robin},
doi = {10.1080/10485252.2012.677843},
issn = {10485252},
journal = {Journal of Nonparametric Statistics},
keywords = {ensemble methods,nonparametric regression,random forests,randomisation,rates of convergence},
title = {{Variance reduction in purely random forests}},
year = {2012}
}
@article{Fischer2018,
abstract = {Long short-term memory (LSTM) networks are a state-of-the-art technique for sequence learning. They are less commonly applied to financial time series predictions, yet inherently suitable for this domain. We deploy LSTM networks for predicting out-of-sample directional movements for the constituent stocks of the S{\&}P 500 from 1992 until 2015. With daily returns of 0.46 percent and a Sharpe ratio of 5.8 prior to transaction costs, we find LSTM networks to outperform memory-free classification methods, i.e., a random forest (RAF), a deep neural net (DNN), and a logistic regression classifier (LOG). The outperformance relative to the general market is very clear from 1992 to 2009, but as of 2010, excess returns seem to have been arbitraged away with LSTM profitability fluctuating around zero after transaction costs. We further unveil sources of profitability, thereby shedding light into the black box of artificial neural networks. Specifically, we find one common pattern among the stocks selected for trading – they exhibit high volatility and a short-term reversal return profile. Leveraging these findings, we are able to formalize a rules-based short-term reversal strategy that yields 0.23 percent prior to transaction costs. Further regression analysis unveils low exposure of the LSTM returns to common sources of systematic risk – also compared to the three benchmark models.},
author = {Fischer, Thomas and Krauss, Christopher},
doi = {10.1016/j.ejor.2017.11.054},
issn = {03772217},
journal = {European Journal of Operational Research},
keywords = {Deep learning,Finance,LSTM,Machine learning,Statistical arbitrage},
title = {{Deep learning with long short-term memory networks for financial market predictions}},
year = {2018}
}
@article{Kucharczyk2019,
abstract = {The Chicago Board Options Exchange (CBOE) Volatility Index, often referred to as VIX Volatility Index (VIX), is considered by many market participants as a common measure of market risk and investors' sentiment. It is also sometimes called the fear index. In general, the VIX represents the market's expectation of the 30-day-ahead looking implied volatility obtained from real-time prices of options on the Standard {\&} Poor's 500 Stock Market Index (S{\&}P500). Over the last few years, many claims about possible VIX manipulations have been brought up by market participants. The increased attention on the VIX has been revived again by unusual trading patterns, which were observed on the market, on the 5 th of February and 18 th of April, 2018. While smaller deviations between implied and realized volatility are a well-known stylized fact of financial markets, large, time-varying differences are also frequently observed throughout the day. In theory, such large deviations might lead to arbitrage opportunities on the VIX market. However, it is hard to exploit as the potential replication strategy requires buying several hundred out-of-the-money (put and call) options on the S{\&}P500. In addition, the Electronic copy available at: https://ssrn.com/abstract=3305686 2 Osterrieder et al. potential list of options used for building the replication strategy constantly changes due to underlying price movements, making it difficult to implement it in real-time. Finally, in most cases, the theoretical replication strategy involves high transaction costs which are driven by illiquid options. This paper discusses a novel approach to replicating and predicting the VIX by using just a subset of the most liquid options. The presented approach is based on a recurrent neural network, more precisely on a long short-term memory (LSTM) model and it uses intraday data of S{\&}P500 options and the VIX. The results can be used to find a much more cost-efficient way of repli-cating the VIX and exploiting any arbitrage opportunities. To the best of the authors' knowledge, this the first paper, that describes a new methodology on how to replicate the VIX (to potentially exploit arbitrage opportunities using VIX futures) and applies most recently developed machine learning models to intraday data of S{\&}P500 options and the VIX. The presented results are supposed to shed more light on the ongoing discussions about possible market manipulations, help other investors to better understand the market and support regulators to investigate market inefficiencies.},
author = {Kucharczyk, Daniel and Osterrieder, Joerg and Rudolf, Silas and Wittwer, Daniel},
doi = {10.2139/ssrn.3305686},
journal = {SSRN Electronic Journal},
title = {{Neural Networks and Arbitrage in the VIX – A Deep Learning Approach for the VIX}},
year = {2019}
}
@book{Abhishek2012,
abstract = {Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives when interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the key ideas and algorithms of reinforcement learning. Their discussion ranges from the history of the field's intellectual foundations to the most recent developments and applications. The only necessary mathematical background is familiarity with elementary concepts of probability. The book is divided into three parts. Part I defines the reinforcement learning problem in terms of Markov decision processes. Part II provides basic solution methods: dynamic programming, Monte Carlo methods, and temporal-difference learning. Part III presents a unified view of the solution methods and incorporates artificial neural networks, eligibility traces, and planning; the two final chapters present case studies and consider the future of reinforcement learning.},
archivePrefix = {arXiv},
arxivId = {1603.02199},
author = {Abhishek, Nandy},
booktitle = {Learning},
doi = {10.1109/MED.2013.6608833},
eprint = {1603.02199},
isbn = {0262193981},
issn = {18726240},
pmid = {17044734},
title = {{Reinforcement learning with Open AI, TensorFlow and Keras Using Python}},
year = {2012}
}
@article{Kim2003,
abstract = {Support vector machines (SVMs) are promising methods for the prediction of -nancial timeseries because they use a risk function consisting of the empirical error and a regularized term
which is derived from the structural risk minimization principle. This study applies SVM to
predicting the stock price index. In addition, this study examines the feasibility of applying SVM
in -nancial forecasting by comparing it withback-propagation neural networks and case-based
reasoning. The experimental results show that SVM provides a promising alternative to stock
market prediction.},
author = {Kim, Kyoung-jae},
journal = {Neurocomputing},
title = {{Predicting Stock Price Direction using Support Vector Machines}},
year = {2003}
}
@article{Dean2018,
abstract = {Abstract: The ending of Moores Law and Dennard scaling has led to the ending of rapid improvement in general-purpose program performance. Machine learning, and in particular deep learning, is an attractive alternative target. It has recently revolutionized vision, speech, language understanding, and many other fields, and promises to help with the grand challenges facing our society. The computation at its core is low-precision linear algebra. Thus, machine learning is both broad enough to apply to many domains, yet narrow enough to benefit from domain-specific architectures, such as Googles TPU. Moreover, the growth in demand for machine learning computing exceeds Moores Law at its peak just as it is fading. Hence, machine learning experts and computer architects must work together to design the computing systems required to deliver on the potential of machine learning. This paper offers motivation, suggestions, and warnings to computer architects on how to best contribute to the machine learning revolution.},
author = {Dean, Jeff and Patterson, David and Young, Cliff},
doi = {10.1109/MM.2018.112130030},
issn = {02721732},
journal = {IEEE Micro},
keywords = {hardware,machine learning,microarchitecture},
title = {{A New Golden Age in Computer Architecture: Empowering the Machine-Learning Revolution}},
year = {2018}
}
@article{Bailey2013,
abstract = {We prove that high simulated performance is easily achievable after backtesting a relatively small number of alternative strategy configurations, a practice we denote “backtest overfitting”. The higher the number of configurations tried, the greater is the probability that the backtest is overfit. Because most financial analysts and academics rarely report the number of configurations tried for a given backtest, investors cannot evaluate the degree of overfitting in most investment proposals. The implication is that investors can be easily misled into allocating capital to strategies that appear to be mathematically sound and empirically supported by an outstanding backtest. Under memory effects, backtest overfitting leads to negative expected returns out-of-sample, rather than zero performance. This may be one of several reasons why so many quantitative funds appear to fail.},
author = {Bailey, David H. and Borwein, Jonathan and {Lopez de Prado}, Marcos and Zhu, Qiji Jim},
doi = {10.2139/ssrn.2308659},
isbn = {9785970405475},
issn = {0002-9920},
journal = {SSRN},
keywords = {E44,G0,G1,G15,G2,G24,Sharpe ratio,backtest,historical simulation,investment strategy,minimum backtest length,optimization,performance degradation,probability of backtest over-fitting},
title = {{Pseudo-Mathematics and Financial Charlatanism: The Effects of Backtest Overfitting on Out-of-Sample Performance}},
year = {2013}
}
@article{Widrow1990,
abstract = {Fundamental developments in feedforward artificial neural networks from the past thirty years are reviewed. The history, origination, operating characteristics, and basic theory of several supervised neural-network training algorithms (including the perceptron rule, the least-mean-square algorithm, three Madaline rules, and the backpropagation technique) are described. The concept underlying these iterative adaptation algorithms is the minimal disturbance principle, which suggests that during training it is advisable to inject new information into a network in a manner that disturbs stored information to the smallest extent possible. The two principal kinds of online rules that have developed for altering the weights of a network are examined for both single-threshold elements and multielement networks. They are error-correction rules, which alter the weights of a network to correct error in the output response to the present input pattern, and gradient rules, which alter the weights of a network during each pattern presentation by gradient descent with the objective of reducing mean-square error (averaged over all training patterns)},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Widrow, Bernard and Lehr, Michael A.},
doi = {10.1109/5.58323},
eprint = {arXiv:1011.1669v3},
isbn = {0321204662},
issn = {15582256},
journal = {Proceedings of the IEEE},
pmid = {15852500},
title = {{30 Years of Adaptive Neural Networks: Perceptron, Madaline, and Backpropagation}},
year = {1990}
}
@misc{Shen2012,
abstract = {Prediction of stock market is a long-time attractive topic to researchers from different fields. In particular, numerous studies have been conducted to predict the movement of stock market using machine learning algorithms such as support vector machine (SVM) and reinforcement learning. In this project, we propose a new prediction algorithm that exploits the temporal correlation among global stock markets and various financial products to predict the next-day stock trend with the aid of SVM. Numerical results indicate a prediction accuracy of 74.4{\%} in NASDAQ, 76{\%} in S{\&}P500 and 77.6{\%} in DJIA. The same algorithm is also applied with different regression algorithms to trace the actual increment in the markets. Finally, a simple trading model is established to study the performance of the proposed prediction algorithm against other benchmarks.},
author = {Shen, Shunrong and Jiang, Haomiao and Zhang, Tongda},
booktitle = {Department of Electrical Engineering, Stanford University},
title = {{Stock market forecasting using machine learning algorithms}},
year = {2012}
}
@article{Reiff2002,
abstract = {Title: Pandas - Powerful Python Data Analysis Toolkit SubTitle: ; Volume: ; Serie: ; Edition: ; Authors: McKinney, Wes And Team, PyData Development ; Year: 2015 ; Pages: 1625 ; Editor: ; Publisher: ; ISBN: ; Keywords: Pandas; Analysis; Data; Toolkit; Powerful; Python ;},
author = {Reiff, Michael I.},
doi = {10.1097/00004703-200210000-00027},
issn = {15367312},
journal = {Journal of Developmental and Behavioral Pediatrics},
title = {{Pandas}},
year = {2002}
}
@article{Hadavandi2010,
abstract = {Stock market prediction is regarded as a challenging task in financial time-series forecasting. The central idea to successful stock market prediction is achieving best results using minimum required input data and the least complex stock market model. To achieve these purposes this article presents an integrated approach based on genetic fuzzy systems (GFS) and artificial neural networks (ANN) for constructing a stock price forecasting expert system. At first, we use stepwise regression analysis (SRA) to determine factors which have most influence on stock prices. At the next stage we divide our raw data into k clusters by means of self-organizing map (SOM) neural networks. Finally, all clusters will be fed into independent GFS models with the ability of rule base extraction and data base tuning. We evaluate capability of the proposed approach by applying it on stock price data gathered from IT and Airlines sectors, and compare the outcomes with previous stock price forecasting methods using mean absolute percentage error (MAPE). Results show that the proposed approach outperforms all previous methods, so it can be considered as a suitable tool for stock price forecasting problems. {\textcopyright} 2010 Elsevier B.V. All rights reserved.},
author = {Hadavandi, Esmaeil and Shavandi, Hassan and Ghanbari, Arash},
doi = {10.1016/j.knosys.2010.05.004},
issn = {09507051},
journal = {Knowledge-Based Systems},
keywords = {Data clustering,Genetic fuzzy systems,Hybrid intelligence model,Self-organizing map (SOM),Stock price forecasting},
title = {{Integration of genetic fuzzy systems and artificial neural networks for stock price forecasting}},
year = {2010}
}
@inproceedings{Juarez2011,
abstract = {They were applied the chaos theory and a complex model of health to determine relationships among aggregate indicators of financial statements. Cash flow, profit and loss, and assets of 70 companies in the sector of crude oil mining and natural gas in Colombia, were analyzed. Natural logs and Lorenz equation were applied to transform cash flow, profit and loss, and assets, resulting in an explained variance of 73{\%} in the linear regression among the new complex indicators. The explained variance without transformations was 6{\%}. However, these transformations make it more difficult to interpret the financial indicators. {\textcopyright} 2010 Published by Elsevier Ltd.},
author = {Ju{\'{a}}rez, Fernando},
booktitle = {Procedia Computer Science},
doi = {10.1016/j.procs.2010.12.161},
issn = {18770509},
keywords = {Chaos theory,Complexity,Financial statements,Health},
title = {{Applying the theory of chaos and a complex model of health to establish relations among financial indicators}},
year = {2011}
}
@misc{Portugal2018,
abstract = {Recommender systems use algorithms to provide users with product or service recommendations. Recently, these systems have been using machine learning algorithms from the field of artificial intelligence. However, choosing a suitable machine learning algorithm for a recommender system is difficult because of the number of algorithms described in the literature. Researchers and practitioners developing recommender systems are left with little information about the current approaches in algorithm usage. Moreover, the development of recommender systems using machine learning algorithms often faces problems and raises questions that must be resolved. This paper presents a systematic review of the literature that analyzes the use of machine learning algorithms in recommender systems and identifies new research opportunities. The goals of this study are to (i) identify trends in the use or research of machine learning algorithms in recommender systems; (ii) identify open questions in the use or research of machine learning algorithms; and (iii) assist new researchers to position new research activity in this domain appropriately. The results of this study identify existing classes of recommender systems, characterize adopted machine learning approaches, discuss the use of big data technologies, identify types of machine learning algorithms and their application domains, and analyzes both main and alternative performance metrics.},
author = {Portugal, Ivens and Alencar, Paulo and Cowan, Donald},
booktitle = {Expert Systems with Applications},
doi = {10.1016/j.eswa.2017.12.020},
issn = {09574174},
keywords = {Application domains,Machine learning,Machine learning algorithms,Performance metrics,Recommender systems,Systematic review of the literature},
title = {{The use of machine learning algorithms in recommender systems: A systematic review}},
year = {2018}
}
@misc{Chollet2015,
abstract = {Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. It was developed with a focus on enabling fast experimentation.},
author = {Chollet, Fran{\c{c}}ois},
booktitle = {Keras.Io},
title = {{Keras: The Python Deep Learning library}},
year = {2015}
}
@article{Making2004,
abstract = {The goal of this writeup is to provide a high-level introduction to the "Kernel Trick" commonly used in classification algorithms such as Support Vector Machines (SVM) and Logistic Regression. My target audience are those who have had some basic experience with machine learning, yet are looking for an alternative introduction to kernel methods.$\backslash$r$\backslash$n$\backslash$r$\backslash$nWe first examine an example that motivates the need for kernel methods. After an explanation about the "Kernel Trick", we finally apply kernels to improve classification results.$\backslash$r$\backslash$n$\backslash$r$\backslash$nThe following code examples are in Python, and make heavy use of the sklearn, numpy, and scipy libraries. I have made the code used in this writeup available - head to the bottom of the article for links to the source files.},
author = {Making, Decision and Jordan, Lecturer Michael I and Rodriguez, Carlos C (Albany) and Hofmann, Martin},
isbn = {0262122413},
journal = {Learning},
title = {{The Kernel Trick}},
year = {2004}
}
@article{Arnott2018,
abstract = {Machine learning offers a set of powerful tools that holds considerable promise for investment management. As with most quantitative applications in finance, the danger of misapplying these techniques can lead to disappointment. One crucial limitation involves data availability. Many of machine learning's early successes originated in the physical and biological sciences, in which truly vast amounts of data are available. Machine learning applications often require far more data than are available in finance, which is of particular concern in longer-horizon investing. Hence, choosing the right applications before applying the tools is important. In addition, capital markets reflect the actions of people, which may be influenced by others' actions and by the findings of past research. In many ways, the challenges that affect machine learning are merely a continuation of the long-standing issues researchers have always faced in quantitative finance. While investors need to be cautious-indeed, more cautious than in past applications of quantitative methods-these new tools offer many potential applications in finance. In this article, the authors develop a research protocol that pertains both to the application of machine learning techniques and to quantitative finance in general.},
author = {Arnott, Robert D. and Harvey, Campbell R. and Markowitz, Harry},
doi = {10.2139/ssrn.3275654},
issn = {1556-5068},
journal = {SSRN Electronic Journal},
title = {{A Backtesting Protocol in the Era of Machine Learning}},
year = {2018}
}
@article{Kara2011,
abstract = {Prediction of stock price index movement is regarded as a challenging task of financial time series prediction. An accurate prediction of stock price movement may yield profits for investors. Due to the complexity of stock market data, development of efficient models for predicting is very difficult. This study attempted to develop two efficient models and compared their performances in predicting the direction of movement in the daily Istanbul Stock Exchange (ISE) National 100 Index. The models are based on two classification techniques, artificial neural networks (ANN) and support vector machines (SVM). Ten technical indicators were selected as inputs of the proposed models. Two comprehensive parameter setting experiments for both models were performed to improve their prediction performances. Experimental results showed that average performance of ANN model (75.74{\%}) was found significantly better than that of SVM model (71.52{\%}). {\textcopyright} 2010 Elsevier Ltd. All rights reserved.},
author = {Kara, Yakup and {Acar Boyacioglu}, Melek and Baykan, {\"{O}}mer Kaan},
doi = {10.1016/j.eswa.2010.10.027},
isbn = {0957-4174},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Artificial neural networks,Prediction,Stock price index,Support vector machines},
pmid = {57533228},
title = {{Predicting direction of stock price index movement using artificial neural networks and support vector machines: The sample of the Istanbul Stock Exchange}},
year = {2011}
}
@article{J.P.Morgan2013,
abstract = {This report covers the various aspects of Risk Factor Investing across different asset classes. The goal of the report's approach to Risk Factor Investing is to create systematic trading strategies while exhibiting low, stable correlations.},
author = {J.P.Morgan},
journal = {Global Quantitative and Derivative Strategy},
title = {{Risk Factor Approach to Investing and Portfolio Management}},
year = {2013}
}
@unpublished{Kumar2006,
abstract = {There exists vast research articles which predict the stock market as well pricing of stock index financial instruments but most of the proposed models focus on the accurate forecasting of the levels (i.e. value) of the underlying stock index. There is a lack of studies examining the predictability of the direction/sign of stock index movement. Given the notion that a prediction with little forecast error does not necessarily translate into capital gain, this study is an attempt to predict the direction of S{\&}P CNX NIFTY Market Index of the National Stock Exchange, one of the fastest growing financial exchanges in developing Asian countries. Random forest and Support Vector Machines (SVM) are very specific type of machine learning method, and are promising tools for the prediction of financial time series. The tested classification models, which predict direction, include linear discriminant analysis, logit, artificial neural network, random forest and SVM. Empirical experimentation suggests that the SVM outperforms the other classification methods in terms of predicting the direction of the stock market movement and random forest method outperforms neural network, discriminant analysis and logit model used in this study.},
author = {Kumar, Manish and Thenmozhi, M.},
booktitle = {SSRN},
doi = {10.2139/ssrn.876544},
keywords = {Forecasting,Random forest,Stock index,Support vector machine},
title = {{Forecasting Stock Index Movement: A Comparison of Support Vector Machines and Random Forest}},
year = {2006}
}
@inproceedings{Czekalski2015,
abstract = {Modern approach to the FOREX currency exchange market requires support from the computer algorithms to manage huge volumes of the transactions and to find opportunities in a vast number of currency pairs traded daily. There are many well known techniques used by market participants on both FOREX and stock-exchange markets (i.e. Fundamental and technical analysis) but nowadays AI based techniques seem to play key role in the automated transaction and decision supporting systems. This paper presents the comprehensive analysis over Feed Forward Multilayer Perceptron (ANN) parameters and their impact to accurately forecast FOREX trend of the selected currency pair. The goal of this paper is to provide information on how to construct an ANN with particular respect to its parameters and training method to obtain the best possible forecasting capabilities. The ANN parameters investigated in this paper include: number of hidden layers, number of neurons in hidden layers, use of constant/bias neurons, activation functions, but also reviews the impact of the training methods in the process of the creating reliable and valuable ANN, useful to predict the market trends. The experimental part has been performed on the historical data of the EUR/USD pair.},
author = {Czekalski, Piotr and Niezabitowski, Michal and Styblinski, Rafal},
booktitle = {Proceedings - 2015 20th International Conference on Control Systems and Computer Science, CSCS 2015},
doi = {10.1109/CSCS.2015.51},
isbn = {9781479917792},
keywords = {ANN,Activation function,FOREX,Network training,Neural network,Perceptron},
title = {{ANN for FOREX forecasting and trading}},
year = {2015}
}
@article{Rojas1997,
abstract = {Provides a detailed description of the architecture of the Z1 and$\backslash$nZ3 computing machines that Konrad Zuse designed in Berlin between 1936$\backslash$nand 1941. The necessary basic information was obtained from a careful$\backslash$nevaluation of the patent application Zuse filed in 1941. Additional$\backslash$ninsight was gained from a software simulation of the machine's logic.$\backslash$nThe Z1 was built using purely mechanical components; the Z3 used$\backslash$nelectromechanical relays. However, both machines shared a common logical$\backslash$nstructure, and their programming model was the same. I argue that both$\backslash$nthe Z1 and the Z3 possessed features akin to those of modern computers:$\backslash$nthe memory and processor were separate units, and the processor could$\backslash$nhandle floating-point numbers and compute the four basic arithmetical$\backslash$noperations as well as the square root of a number. The program was$\backslash$nstored on punched tape and was read sequentially. In the last section of$\backslash$nthis paper, I put the architecture of the Z1 and Z3 into historical$\backslash$nperspective by offering a comparison with computing machines built in$\backslash$nother countries},
author = {Rojas, Ra{\'{u}}l},
doi = {10.1109/85.586067},
issn = {10586180},
journal = {IEEE Annals of the History of Computing},
title = {{Konrad Zuse's legacy: The architecture of the Z1 and Z3}},
year = {1997}
}
@article{Bergmeir2012,
abstract = {In time series predictor evaluation, we observe that with respect to the model selection procedure there is a gap between evaluation of traditional forecasting procedures, on the one hand, and evaluation of machine learning techniques on the other hand. In traditional forecasting, it is common practice to reserve a part from the end of each time series for testing, and to use the rest of the series for training. Thus it is not made full use of the data, but theoretical problems with respect to temporal evolutionary effects and dependencies within the data as well as practical problems regarding missing values are eliminated. On the other hand, when evaluating machine learning and other regression methods used for time series forecasting, often cross-validation is used for evaluation, paying little attention to the fact that those theoretical problems invalidate the fundamental assumptions of cross-validation. To close this gap and examine the consequences of different model selection procedures in practice, we have developed a rigorous and extensive empirical study. Six different model selection procedures, based on (i) cross-validation and (ii) evaluation using the series' last part, are used to assess the performance of four machine learning and other regression techniques on synthetic and real-world time series. No practical consequences of the theoretical flaws were found during our study, but the use of cross-validation techniques led to a more robust model selection. To make use of the "best of both worlds", we suggest that the use of a blocked form of cross-validation for time series evaluation became the standard procedure, thus using all available information and circumventing the theoretical problems. {\textcopyright} 2012 Elsevier Inc. All rights reserved.},
author = {Bergmeir, Christoph and Ben{\'{i}}tez, Jos{\'{e}} M.},
doi = {10.1016/j.ins.2011.12.028},
issn = {00200255},
journal = {Information Sciences},
keywords = {Cross-validation,Error measures,Machine learning,Predictor evaluation,Regression,Time series},
title = {{On the use of cross-validation for time series predictor evaluation}},
year = {2012}
}
@article{Corhay1996,
abstract = {Stock returns series generally exhibit time-varying volatility. Therefore, one can cast doubt on the way abnormal returns are calculated and consequently interpreted in traditional event studies. In this paper we apply a market model which accounts for GARCH effects leading to more efficient estimators. Using a sample of divestitures, we empirically investigate how this adjustment affects the magnitude of the abnormal returns associated with an event. {\textcopyright} 1996 Board of Trustees of the University of Illinois.},
author = {Corhay, A. and Rad, A. Tourani},
doi = {10.1016/S1062-9769(96)90050-2},
issn = {10629769},
journal = {Quarterly Review of Economics and Finance},
title = {{Conditional heteroskedasticity adjusted market model and an event study}},
year = {1996}
}
