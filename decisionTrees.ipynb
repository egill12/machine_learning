{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Decision trees\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "#import graphviz\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the data that we want to create a DT on.\n",
    "# import the fx data , econ and value data for EURUSD.\n",
    "# then create the features (on trend and econ data) standardise and run a DT on the x_train sample.\n",
    "# what is  target? 1 day ahead or long days ahead? trade on binary data.\n",
    "csv_file = {\"FXData\" : r\"C:\\Users\\edgil\\Documents\\Masters\\dissertation\\data\\CurrencyData.csv\",\n",
    "            \"ValueData\" : r\"\",\n",
    "            \"EconData\" : r\"\",\n",
    "            }\n",
    "fxdata = pd.read_csv(csv_file[\"FXData\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this to make sure the dates are imported correctly as UK dates\n",
    "fxdata['Date'] = pd.to_datetime(fxdata['Date'], format= '%d/%m/%Y %H:%M')\n",
    "# Separate out the EURUSD factor\n",
    "eurusd = fxdata[[\"Date\", \"EURUSD\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edgil\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  \nC:\\Users\\edgil\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  # This is added back by InteractiveShellApp.init_path()\nC:\\Users\\edgil\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  if sys.path[0] == '':\nC:\\Users\\edgil\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  del sys.path[0]\nC:\\Users\\edgil\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  \nC:\\Users\\edgil\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# Build out the featur set on price, this may need to be created using funcional process.\n",
    "eurusd[\"logret\"] = np.log(eurusd[\"EURUSD\"]) - np.log(eurusd[\"EURUSD\"].shift(1))\n",
    "# Standardising the daily rets and accumulating the standardised returns, or should we sum the % ret and standardise by its own history\n",
    "# is difference between different accumulated retusn horizons the same as the macd?\n",
    "# should we standardise by the 1 year forward vol?\n",
    "targetlkbk = 5\n",
    "lkbk1M = 22\n",
    "lkbk3M = 66\n",
    "lkbk6M = 132\n",
    "lkbk9M = 198\n",
    "eurusd['1MRet'] = eurusd[\"logret\"].rolling(lkbk1M).sum()\n",
    "eurusd['3MRet'] = eurusd[\"logret\"].rolling(lkbk3M).sum()\n",
    "eurusd['6MRet'] = eurusd[\"logret\"].rolling(lkbk6M).sum()\n",
    "eurusd['9MRet'] = eurusd[\"logret\"].rolling(lkbk9M).sum()\n",
    "eurusd['1Mv3MRet'] = eurusd[\"1MRet\"].sub(eurusd[\"3MRet\"])\n",
    "eurusd['1Mv6MRet'] = eurusd[\"1MRet\"].sub(eurusd[\"6MRet\"])\n",
    "# create a target vector to train on.\n",
    "# must think deeply about what this will look like\n",
    "# to start, this is a 1M forard return calculation, is it right to use overlapping 1M fwd rets? it seems not...\n",
    "eurusd[\"target\"] = eurusd['logret'].iloc[::-1].rolling(targetlkbk).sum().values[::-1]\n",
    "eurusd['target_binary'] = eurusd['target'].apply(np.sign) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Very important step is to truncate the data so that we do not see the last 1 year of data.\n",
    "# Q. should we not have a rollign window type of model? or just always aggregate the data from the start?\n",
    "# how ong is testing? we should we the train and test to sizes which make sense to the type of model we use going forward.\n",
    "eurusd = eurusd.loc[eurusd['Date'] < \"2018-01-01 00:00\"]\n",
    "# train size should be at least 5 years?\n",
    "eurusd_train = eurusd.loc[eurusd['Date'] < \"2003-01-01 00:00\"]\n",
    "eurusd_test = eurusd.loc[eurusd['Date'] > \"2010-02-01 00:00\"]\n",
    "# create a target vector to train on.\n",
    "# must think deeply about what this will look like\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18768, 8)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardise the data using sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# standardise the data now.\n",
    "# remove dates\n",
    "data_cols = [col for col in eurusd_train.columns if col not in [\"Date\", \"target\", \"target_binary\"]]\n",
    "data_train = eurusd_train.loc[:, data_cols]\n",
    "data_test = eurusd_test.loc[:, data_cols]\n",
    "eurusd_train_normed = pd.DataFrame(scaler.fit_transform(data_train), columns = list(data_train.columns))\n",
    "eurusd_test_normed = pd.DataFrame(scaler.transform(data_test), columns = list(data_test.columns)) \n",
    "#print(eurusd_train_normed.tail(50))\n",
    "eurusd_train_normed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### This is where we choose and set up the models!\n",
    "# need to re do the models here.\n",
    "X = eurusd_train_normed[['1Mv3MRet', \"1Mv6MRet\"]]\n",
    "Y = eurusd_train[\"target_binary\"]\n",
    "X_test = eurusd_test_normed\n",
    "Y_test = eurusd_test[\"target_binary\"]\n",
    "# clean the data and nan values\n",
    "X = X.replace(np.nan, 0)\n",
    "Y = Y.replace(np.nan, 0)\n",
    "X_test = X_test.replace(np.nan, 0)\n",
    "Y_test = Y_test.replace(np.nan, 0)\n",
    "#RF = RandomForestClassifier(n_estimators = 150, max_features = 5)\n",
    "#RF.fit(X, Y)\n",
    "clf = tree.DecisionTreeClassifier(max_leaf_nodes = 6, max_depth = 8)\n",
    "clf = clf.fit(X, Y)\n",
    "#tree.export_graphviz(clf, out_file='tree.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualise the data\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "\n",
    "dot_data = StringIO()\n",
    "\"\"\"export_graphviz(clf, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True)\n",
    "                \"\"\"\n",
    "tree.export_graphviz(clf, out_file=dot_data, class_names=['Sell',\"Hold\",\"Buy\"]\n",
    "                     , filled=True, rounded=True, special_characters = True) \n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue()) \n",
    "graph.write_pdf(\"treey.pdf\") \n",
    "#graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "#Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'round-table.gv.pdf'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rough work\n",
    "#eurusd = eurusd.replace(np.nan, 0)\n",
    "#print(eurusd.tail(25))\n",
    "#eurusd[\"target\"] = eurusd['logret'].iloc[::-1].rolling(2).sum().values[::-1]\n",
    "#print(eurusd.head(10))\n",
    "#data_cols = [col for col in eurusd_train.columns if col not in [\"Date\", \"target\", \"target_binary\"]]\n",
    "#print(data_cols)\n",
    "from graphviz import Digraph\n",
    "\n",
    "dot = Digraph(comment=\"The round table\")\n",
    "dot.node('A', 'King Arthur')\n",
    "dot.node('B', 'Sir Bedevere the Wise')\n",
    "dot.node('L', 'Sir Lancelot the Brave')\n",
    "dot.render('round-table.gv', view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(Y.loc[X['1Mv3MRet'] > 0.92])\n",
    "#clf.feature_importances_\n",
    "round(1 - ((152/304)**2 + + (152/304)**2),3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
