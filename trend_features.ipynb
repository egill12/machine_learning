{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this file creates the features used in the trend RNN.\n",
    "# features will revolve around high frequency (intra-day) mid-freq (daily to weekly), long term ( monthly trends)\n",
    "# for the intraday factor, should we try for minutely data?\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime \n",
    "from scipy.stats import norm\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "# Set up the data that we want to create a DT on.\n",
    "# import the fx data , econ and value data for EURUSD.\n",
    "# then create the features (on trend and econ data) standardise and run a DT on the x_train sample.\n",
    "# what is  target? 1 day ahead or long days ahead? trade on binary data.\n",
    "csv_file = {\"FXData\" : r\"C:\\Users\\edgil\\Documents\\Masters\\dissertation\\data\\CurrencyData.csv\",\n",
    "            \"ValueData\" : r\"\",\n",
    "            \"EconData\" : r\"\",\n",
    "            }\n",
    "fxdata = pd.read_csv(csv_file[\"FXData\"])\n",
    "fxdata['Date'] = pd.to_datetime(fxdata['Date'], format= '%d/%m/%Y %H:%M')\n",
    "# Separate out the EURUSD factor\n",
    "eurusd = fxdata[[\"Date\", \"EURUSD\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Very important step is to truncate the data so that we do not see the last 1 year of data.\n",
    "# Q. should we not have a rollign window type of model? or just always aggregate the data from the start?\n",
    "# how ong is testing? we should we the train and test to sizes which make sense to the type of model we use going forward.\n",
    "eurusd = eurusd.loc[eurusd['Date'] < \"2018-01-01 00:00\"]\n",
    "# train size should be at least 5 years?\n",
    "eurusd_train = eurusd.loc[eurusd['Date'] < \"2003-01-01 00:00\"]\n",
    "eurusd_test = eurusd.loc[eurusd['Date'] > \"2010-02-01 00:00\"]\n",
    "# create a target vector to train on.\n",
    "# must think deeply about what this will look like\n",
    "# Build out the featur set on price, this may need to be created using funcional process.\n",
    "eurusd[\"logret\"] = np.log(eurusd[\"EURUSD\"]) - np.log(eurusd[\"EURUSD\"].shift(1))\n",
    "# Standardising the daily rets and accumulating the standardised returns, or should we sum the % ret and standardise by its own history\n",
    "# is difference between different accumulated retusn horizons the same as the macd?\n",
    "# should we standardise by the 1 year forward vol?\n",
    "targetlkbk = 5\n",
    "short = 5\n",
    "medium = 15\n",
    "long = 55\n",
    "longest = 100\n",
    "eurusd['HF_short'] = eurusd[\"EURUSD\"].rolling(short).ewma()\n",
    "eurusd['HF_medium'] = eurusd[\"EURUSD\"].rolling(medium).ewma()\n",
    "eurusd['HF_long'] = eurusd[\"EURUSD\"].rolling(long).ewma()\n",
    "eurusd['HF_longest'] = eurusd[\"EURUSD\"].rolling(longest).ewma()\n",
    "# differences to spot\n",
    "eurusd['spot_v_HF_short'] = eurusd[\"EURUSD\"] - eurusd['HF_short']\n",
    "eurusd['spot_v_HF_medium'] = eurusd[\"EURUSD\"] - eurusd['HF_medium']\n",
    "eurusd['spot_v_HF_long'] = eurusd[\"EURUSD\"] - eurusd['HF_long']\n",
    "eurusd['spot_v_HF_longest'] = eurusd[\"EURUSD\"] - eurusd['HF_longest'] \n",
    "\n",
    "\n",
    "\n",
    "# average of both spot distance and each ema distance\n",
    "# medium frequency factors, multiplyer allows us to scale up the lookback as needed.\n",
    "# days to weeks\n",
    "medium_multiplyer = 24\n",
    "eurusd['MF_short'] = eurusd[\"EURUSD\"].rolling(short*medium_multiplyer).ewma()\n",
    "eurusd['MF_medium'] = eurusd[\"EURUSD\"].rolling(medium*medium_multiplyer).ewma()\n",
    "eurusd['MF_long'] = eurusd[\"EURUSD\"].rolling(long*medium_multiplyer).ewma()\n",
    "eurusd['MF_longest'] = eurusd[\"EURUSD\"].rolling(longest*medium_multiplyer).ewma()\n",
    "# differences to spot\n",
    "eurusd['spot_v_MF_short'] = eurusd[\"EURUSD\"] - eurusd['MF_short']\n",
    "eurusd['spot_v_MF_medium'] = eurusd[\"EURUSD\"] - eurusd['MF_medium']\n",
    "eurusd['spot_v_MF_long'] = eurusd[\"EURUSD\"] - eurusd['MF_long']\n",
    "eurusd['spot_v_MF_longest'] = eurusd[\"EURUSD\"] - eurusd['MF_longest'] \n",
    "# long term factors\n",
    "# weeks to months\n",
    "long_multiplyer = 120 # each period is now one business week, 24*5\n",
    "eurusd['LF_short'] = eurusd[\"EURUSD\"].rolling(short*medium_multiplyer).ewma()\n",
    "eurusd['LF_medium'] = eurusd[\"EURUSD\"].rolling(medium*medium_multiplyer).ewma()\n",
    "eurusd['LF_long'] = eurusd[\"EURUSD\"].rolling(long*medium_multiplyer).ewma()\n",
    "eurusd['LF_longest'] = eurusd[\"EURUSD\"].rolling(longest*medium_multiplyer).ewma()\n",
    "# differences to spot\n",
    "eurusd['spot_v_LF_short'] = eurusd[\"EURUSD\"] - eurusd['LF_short']\n",
    "eurusd['spot_v_LF_medium'] = eurusd[\"EURUSD\"] - eurusd['LF_medium']\n",
    "eurusd['spot_v_LF_long'] = eurusd[\"EURUSD\"] - eurusd['LF_long']\n",
    "eurusd['spot_v_LF_longest'] = eurusd[\"EURUSD\"] - eurusd['LF_longest'] \n",
    "\n",
    "# take simple average of the divergences\n",
    "eurusd['spot_v_HF'] = (eurusd['spot_v_HF_short'] + eurusd['spot_v_HF_medium'] + eurusd['spot_v_HF_long'] + eurusd['spot_v_HF_longest'])/4\n",
    "eurusd['spot_v_MF'] = (eurusd['spot_v_MF_short'] + eurusd['spot_v_MF_medium'] + eurusd['spot_v_MF_long'] + eurusd['spot_v_MF_longest'])/4\n",
    "eurusd['spot_v_LF'] = (eurusd['spot_v_LF_short'] + eurusd['spot_v_LF_medium'] + eurusd['spot_v_LF_long'] + eurusd['spot_v_LF_longest'])/4 \n",
    "#differences to each ema\n",
    "eurusd['HF_ema_short_diff'] = eurusd['HF_short']  - eurusd['HF_medium'] - eurusd['HF_long'] - eurusd['HF_long'] - eurusd['HF_longest']\n",
    "eurusd['MF_ema_short_diff'] = eurusd['MF_short'] - eurusd['MF_medium'] - eurusd['MF_long'] - eurusd['MF_long'] - eurusd['MF_longest']\n",
    "eurusd['LF_ema_short_diff'] = eurusd['LF_short'] - eurusd['LF_medium'] - eurusd['LF_long'] - eurusd['LF_long'] - eurusd['LF_longest']\n",
    "# create a target vector to train on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features for high frequency periods.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
